<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Ansible Collaborative Website">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Ansible Collaborative (old posts, page 4) | Ansible Collaborative</title>
<link href="../assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/baguetteBox.min.css" rel="stylesheet" type="text/css">
<link href="../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<!-- Red Hat fonts --><link rel="stylesheet" href="https://static.redhat.com/libs/redhat/redhat-font/2.0.0/webfonts/red-hat-font.css">
<!-- Font Awesome --><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css" integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">
<!-- Fork Awesome --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css" integrity="sha256-XoaMnoYC5TH6/+ihMEnospgm0J1PM/nioxbOUdnM8HY=" crossorigin="anonymous">
<!-- Sass compiled css  --><link rel="stylesheet" href="../assets/css/main.css">
<link rel="stylesheet" href="../assets/css/redhat-footer.css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://ansible.com/blog/index-4.html">
<link rel="prev" href="index-5.html" type="text/html">
<link rel="next" href="index-3.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->
</head>
<body id="top">

<div class="global-container" id="content" role="main">
<!-- Start menubar -->
<nav class="navbar navbar-expand-lg static-top mb-4 navbar-padding full-width-bg   navbar-dark   bg-pool   "><div class="masthead">
    <!-- This keeps the margins nice -->
    <a class="navbar-brand" href="../">
        <img src="../images/ansible_logo-small-15.png" alt="Ansible community logo" id="logo" class="d-inline-block align-top" width="50" height="50"></a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon nav-toggle-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="bs-navbar">
      <ul class="navbar-nav mr-auto"></ul>
<ul class="navbar-nav navbar-right">
<li class="nav-item dropdown">
	        <a href="#" class="nav-link nav-link-color dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
		    <i class=""></i> Documentation
                </a>
		<div class="dropdown-menu dropdown-menu-border">
	    
                    <a href="https://docs.ansible.com/" class="dropdown-item">
		        <i class=""></i> Project documentation
                    </a>
                    <a href="https://access.redhat.com/documentation/en-us/red_hat_ansible_automation_platform/" class="dropdown-item">
		        <i class=""></i> Ansible Automation Platform documentation
                    </a>
            </div>
                 </li>
<li class="nav-item">
		     <a href="https://galaxy.ansible.com/" target="_blank" class="nav-link nav-link-color">
		         <i class=""></i> Galaxy
		     </a>
		 </li>
                 <li class="nav-item">
		     <a href="https://forum.ansible.com/" target="_blank" class="nav-link nav-link-color">
		         <i class=""></i> Forum
		     </a>
		 </li>
            <li class="nav-item dropdown">
	        <a href="#" class="nav-link nav-link-color dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
		    <i class=""></i> Resources
                </a>
		<div class="dropdown-menu dropdown-menu-border">
	    
                    <a href="../how-ansible-works/" class="dropdown-item">
		        <i class=""></i> How Ansible works
                    </a>
                    <a href="../ecosystem/" class="dropdown-item">
		        <i class=""></i> Ansible ecosystem
                    </a>
                    <a href="archive.html" class="dropdown-item">
		        <i class=""></i> Blog
                    </a>
                    <a href="../faq/" class="dropdown-item">
		        <i class=""></i> Frequently asked questions
                    </a>
                    <a href="../ansible-community-training/" class="dropdown-item">
		        <i class=""></i> Ansible community training
                    </a>
                    <a href="../contact-us/" class="dropdown-item">
		        <i class=""></i> Contact us
                    </a>
            </div>
                 </li>
<li class="nav-item">
		     <a href="https://www.redhat.com/en/technologies/management/ansible?sc_cid=7015Y000003szaKQAQ" target="_blank" class="nav-link nav-link-color">
		         <i class=""></i> Ansible Automation Platform
		     </a>
		 </li>

        
      </ul>
</div>
    <!-- /.navbar-collapse -->
  </div>
  <!-- /.container -->
</nav><!-- End default Menubar --><div class="body-content center-band">
        <!--Body content-->
        
    
  <div class="postindex ansible-content">
      <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="using-ansible-automation-platform-gitlab-ce-and-webhooks-to-deploy-iis-website/" class="u-url">Using Ansible Automation Platform, GitLab CE and webhooks to deploy IIS website</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/colin-mcnaughton/">Colin McNaughton</a>
              </span>
            </p>
            <p class="dateline">
              <a href="using-ansible-automation-platform-gitlab-ce-and-webhooks-to-deploy-iis-website/" rel="bookmark">
                <time class="published dt-published" datetime="2020-03-17T00:00:00Z" itemprop="datePublished" title="2020-03-17 00:00">2020-03-17 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>Using Ansible Automation Platform, GitLab CE and webhooks to deploy IIS website</h2>
<p>Inside Red Hat Ansible Automation Platform, the Ansible Tower REST API
is the key mechanism that helps enable automation to be integrated into
processes or tools that exist in an environment. With Ansible Tower 3.6
we have brought direct integration with webhooks from GitHub and GitLab,
including the enterprise on-premises versions. This means that changes
in source control can trigger automation to apply changes to
infrastructure configuration, deploy new services, reconfigure existing
applications, and more. In this blog, I'll run through a simple scenario
and apply the new integrated webhook feature.</p>
<h2>Environment</h2>
<p>My environment consists of Ansible Tower (one component of Red Hat
Ansible Automation Platform), GitLab CE with a project already created,
and a code server running an IDE with the same git repository cloned. A
single inventory exists on Ansible Tower with just one host, an instance
of Windows 2019 Server running on a certified cloud. For this example,
I'm going to deploy IIS on top of this Windows server and make some
modifications to the html file that I'd like to serve from this site. </p>
<p>My playbook to deploy IIS is <em>very</em> simple:</p>
<div class="code"><pre class="code literal-block"> ---
<span class="k">-</span> name: Configure IIS
  hosts: windows

  tasks:
  <span class="k">-</span> name: Install IIS
    win_feature:
      name: Web-Server
      state: present

  <span class="k">-</span> name: Start IIS service
    win_service:
      name: W3Svc
      state: started

  <span class="k">-</span> name: Create website index.html
    win_copy:
      src: files/web.html
      dest: C:\Inetpub\wwwroot\index.html
</pre></div>

<p>All that I am doing here is adding the <code>Web-Server</code> feature, starting
IIS and copying my site's html file to the default location for web
content being served by IIS. </p>
<p>My html file is just as basic:</p>
<div class="code"><pre class="code literal-block"><span class="p">&lt;</span><span class="nt">html</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">title</span><span class="p">&gt;&lt;/</span><span class="nt">title</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">body</span><span class="p">&gt;</span>

<span class="p">&lt;/</span><span class="nt">body</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">html</span><span class="p">&gt;</span>
</pre></div>

<h3>Objective and setup</h3>
<p>What I would like to happen is that, for each merge request that makes
changes to this one IIS site, the site should be redeployed with this
basic html file.</p>
<p><img alt="Colin blog new one" src="../images/posts/archive/colin-blog-new-one.png"></p>
<h3>GitLab Access Token</h3>
<p>As my webhook is triggered, I would like to update the merge request
created in GitLab with the status of my Ansible Tower job. </p>
<p>To accomplish this, I first have to create a personal access token for
my GitLab account so that Ansible Tower can access the GitLab API. This
is pretty painless. All I have to do is navigate to my user settings and
select "Access Tokens" from the left side navigation panel:</p>
<p><img alt="Colin blog two" src="../images/posts/archive/colin-blog-two.png"></p>
<p>I give my access token an easily recognizable name of "Ansible Tower,"
set the expiration date to the end of the month, and scope this access
token to just the API. Upon clicking "Create personal access token," the
token itself becomes visible and a new entry is shown at the bottom of
this page:</p>
<p><img alt="Colin blog three" src="../images/posts/archive/colin-blog-three.png"></p>
<p>Next, I will use this token to create a new credential in Ansible Tower
of type "GitLab Personal Access Token":</p>
<p><img alt="Colin blog four" src="../images/posts/archive/colin-blog-four.png"></p>
<p>Upon saving, Ansible Tower now has API access to my GitLab account. </p>
<h3>Ansible Tower Job Template</h3>
<p>Now that Ansible Tower has the ability to update my merge requests, I
need to configure webhook access to my job template that is configured
to run my simple IIS playbook. Since the Ansible Tower 3.6 release,
there is now a checkbox on each job template called <strong>ENABLE WEBHOOK</strong>.</p>
<p><img alt="coling blog new three" src="../images/posts/archive/colin-blog-new-three.png"></p>
<p>Once I select the option to <strong>ENABLE WEBHOOK</strong> I am presented with a few
new fields. I select GitLab as my <strong>WEBHOOK SERVICE</strong>, supply the
credential I created using my GitLab personal access token, <strong>WEBHOOK
URL</strong> is prepopulated with the path to this job template and, upon
saving my modifications, a <strong>WEBHOOK KEY</strong> is generated which I will use
to configure the project hook in GitLab. Also, note that my project
allows me to override the SCM branch. This means that the project will
pull updates from the "change-web-text" branch instead of Master. </p>
<h3>GitLab Project Hook integration</h3>
<p>The next step takes me back to GitLab, this time navigating to the
integrations page of the project I would like to execute the webhook.</p>
<p><img alt="Colin blog six" src="../images/posts/archive/colin-blog-six.png"></p>
<p>On the integrations page, I supply the URL (<strong>WEBHOOK URL</strong> from my job
template in Ansible Tower) and Secret Token (<strong>WEBHOOK KEY</strong> from my job
template in Ansible Tower). I also specify the Trigger as "Merge request
events" which means that the URL I specified will be launched anytime a
merge request is opened.</p>
<p><img alt="colin blog new two" src="../images/posts/archive/colin-blog-new-two.png"></p>
<h3>In action: Updating my website text</h3>
<p>Now that I've given Ansible Tower access to my projects using a personal
access token as a new credential type, configured my job template to
enable webhooks, and configured a Project Hook on GitLab to respond to
merge request events on my project, I'm ready to make a test commit of
my html file.</p>
<p>Here, I add text to the <code>&lt;title&gt;</code> and <code>&lt;body&gt;</code> tags of my html
document and save the file:</p>
<p><img alt="Colin blog eight" src="../images/posts/archive/colin-blog-eight.png"></p>
<p>Once I've committed my change on my "change-web-text" branch, I will
push my code, go back to GitLab and open a merge request to merge
changes back into master.</p>
<p><img alt="colin new blog" src="../images/posts/archive/colin-new-blog.png"></p>
<p>Opening this merge request will now trigger my webhook which will deploy
my web page changes to my IIS site. Because I have configured Ansible
Tower with my personal access token, Ansible Tower will post a link to
the job executed as a result of the webhook trigger on the merge
request.</p>
<p>If all has been configured correctly, I should see a new job being
executed that corresponds to the job template with the configured
webhook. I should also see a job that has been kicked off, updating my
project which will pull in the latest changes from my GitLab project.</p>
<p><img alt="Colin blog nine" src="../images/posts/archive/colin-blog-nine.png"></p>
<p>Selecting the job for "iis website create", which is the job template I
configured for webhook execution, shows that the job was <strong>LAUNCHED BY</strong>
webhook. <strong>EXTRA VARIABLES</strong> will show a lot of project specific
configuration facts, and more importantly the job output should show
that the job is executing what it's supposed to.</p>
<p><img alt="Colin blog ten" src="../images/posts/archive/colin-blog-ten.png"></p>
<p>Upon completion, I should be able to pull up the IP of my IIS server and
see the changes to my incredible html page:</p>
<p><img alt="Colin blog eleven" src="../images/posts/archive/colin-blog-eleven.png"></p>
<h3>Takeaways</h3>
<p>Webhooks introduced in Ansible Tower 3.6 are an incredibly powerful way
to launch automation in response to events in source control. While this
basic website is just a very quick and simple example, applying this
functionality to infrastructure as code where all service configurations
are defined in Ansible Playbooks greatly emphasizes this robust feature.</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="deep-dive-on-vlans-resource-modules-for-network-automation/" class="u-url">Deep dive on VLANS resource modules for network automation</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/sean-cavanaugh/">Sean Cavanaugh</a>
              </span>
            </p>
            <p class="dateline">
              <a href="deep-dive-on-vlans-resource-modules-for-network-automation/" rel="bookmark">
                <time class="published dt-published" datetime="2020-02-19T00:00:00Z" itemprop="datePublished" title="2020-02-19 00:00">2020-02-19 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>Deep dive on VLANS resource modules for network automation</h2>
<p>In October of 2019, as part of Red Hat Ansible Engine 2.9, the Ansible
Network Automation team introduced the concept of resource modules. 
These opinionated network modules make network automation easier and
more consistent for those automating various network platforms in
production.  The goal for resource modules was to avoid creating overly
complex jinja2 templates for rendering network configuration. This blog
post goes through the eos_vlans module for the Arista EOS network
platform.  I walk through several examples and describe the use cases
for each state parameter and how we envision these being used in real
world scenarios.</p>
<p>Before starting let's quickly explain the rationale behind naming of the
network resource modules. Notice for resource modules that configure
VLANs there is a singular form (eos_vlan, ios_vlan, junos_vlan, etc) and
a plural form (eos_vlans, ios_vlans, junos_vlans).  The new resource
modules are the plural form that we are covering today. We have
deprecated the singular form. This was done so that those using existing
network modules would not have their Ansible Playbooks stop working and
have sufficient time to migrate to the new network automation modules.</p>
<h3>VLAN Example</h3>
<p>Let's start with an example of the
<a href="https://docs.ansible.com/ansible/latest/modules/eos_vlans_module.html">eos_vlans</a>
resource module:</p>
<div class="code"><pre class="code literal-block">---
<span class="k">-</span> name: add vlans
  hosts: arista
  gather_facts: false
  tasks:
    <span class="k">-</span> name: add VLAN configuration
      eos_vlans:
        config:
          <span class="k">-</span> name: desktops
            vlan_id: 20
          <span class="k">-</span> name: servers
            vlan_id: 30
          <span class="k">-</span> name: printers
            vlan_id: 40
          <span class="k">-</span> name: DMZ
            vlan_id: 50
</pre></div>

<p>There is an implicit state parameter which defaults to merged (i.e.
state: merged).  If we run this Ansible Playbook VLANs 20,30,40 and 50
will be merged into the running configuration of any device in the
arista group.  The show vlan output on a new Arista switch will look
like the following:</p>
<div class="code"><pre class="code literal-block">rtr2#show<span class="w"> </span>vlan
VLAN<span class="w">  </span>Name<span class="w">                             </span>Status<span class="w">    </span>Ports
-----<span class="w"> </span>--------------------------------<span class="w"> </span>---------<span class="w"> </span>-------------------------------
<span class="m">1</span><span class="w">     </span>default<span class="w">                          </span>active
<span class="m">20</span><span class="w">    </span>desktops<span class="w">                         </span>active
<span class="m">30</span><span class="w">    </span>servers<span class="w">                          </span>active
<span class="m">40</span><span class="w">    </span>printers<span class="w">                         </span>active
<span class="m">50</span><span class="w">    </span>DMZ<span class="w">                              </span>active
</pre></div>

<p>while the running configuration will look like the following:</p>
<div class="code"><pre class="code literal-block">rtr2#show<span class="w"> </span>running-config<span class="w"> </span><span class="p">|</span><span class="w"> </span>s<span class="w"> </span>vlan
vlan<span class="w"> </span><span class="m">20</span>
<span class="w">   </span>name<span class="w"> </span>desktops
!
vlan<span class="w"> </span><span class="m">30</span>
<span class="w">   </span>name<span class="w"> </span>servers
!
vlan<span class="w"> </span><span class="m">40</span>
<span class="w">   </span>name<span class="w"> </span>printers
!
vlan<span class="w"> </span><span class="m">50</span>
<span class="w">   </span>name<span class="w"> </span>DMZ
</pre></div>

<p>Now let's make a change manually to the network configuration:</p>
<div class="code"><pre class="code literal-block">rtr2<span class="o">(</span>config<span class="o">)</span><span class="c1">#vlan 100</span>
rtr2<span class="o">(</span>config-vlan-100<span class="o">)</span><span class="c1">#name artisanal_vlan</span>
rtr2<span class="o">(</span>config-vlan-100<span class="o">)</span><span class="c1">#end</span>
rtr2#wr
Copy<span class="w"> </span>completed<span class="w"> </span>successfully.
</pre></div>

<p>If I re-run the Ansible Playbook it returns with changed=0 because it
only cares about the VLANs 20, 30, 40 and 50. It won't remove VLAN 100
because we have the state parameter set to merged by default, so it only
will merged the data model it knows about. It is just enforcing
configuration policy of the VLANs I am sending.</p>
<h3>Using the 'state' parameter</h3>
<p>What happens if I change the state parameter to replaced?  Just change
the previous example to the following:</p>
<div class="code"><pre class="code literal-block">---
<span class="k">-</span> name: add vlans
  hosts: arista
  gather_facts: false
  tasks:
    <span class="k">-</span> name: add VLAN configuration
      eos_vlans:
        state: replaced
        config:
          <span class="k">-</span> name: desktops
            vlan_id: 20
          <span class="k">-</span> name: servers
            vlan_id: 30
          <span class="k">-</span> name: printers
            vlan_id: 40
          <span class="k">-</span> name: DMZ
            vlan_id: 50
</pre></div>

<p>The Ansible Playbook ran just like before with changed=0. Can we tell if
it removed the artisanal_vlan 100?</p>
<div class="code"><pre class="code literal-block">rtr2#show<span class="w"> </span>vlan
VLAN<span class="w">  </span>Name<span class="w">                             </span>Status<span class="w">    </span>Ports
-----<span class="w"> </span>--------------------------------<span class="w"> </span>---------<span class="w"> </span>-------------------------------
<span class="m">1</span><span class="w">     </span>default<span class="w">                          </span>active
<span class="m">20</span><span class="w">    </span>desktops<span class="w">                         </span>active
<span class="m">30</span><span class="w">    </span>servers<span class="w">                          </span>active
<span class="m">40</span><span class="w">    </span>printers<span class="w">                         </span>active
<span class="m">50</span><span class="w">    </span>DMZ<span class="w">                              </span>active
<span class="m">100</span><span class="w">   </span>artisanal_vlan<span class="w">                   </span>active
</pre></div>

<p>Nope! The goal of resource modules is to update existing resources to
match the existing data model. Since our data model (the key, value
pairs that represent the VLANs, which are passed under the config
parameter in the playbook) only includes VLANs 20, 30, 40 and 50 the
eos_vlans module only updates parameters relevant to those particular
VLANs.</p>
<p>Why would I use this versus a merged? The major difference between a
merged and a replaced is that a merged just makes sure the commands are
present that are represented within the data model, whereas the replaced
parameter makes your resource match the data model. Let\'s look at the
eos_vlans module to see what it considers as part of the vlans resource.</p>
<p>There are three parameters currently used for the <strong>vlans</strong> resource:</p>
<ul>
<li>name</li>
<li>state (active or suspend)</li>
<li>vlan_id (range between 1-4094)</li>
</ul>
<p>Let's look at the following example:</p>
<p><strong>Data Model Sent</strong></p>
<div class="code"><pre class="code literal-block"><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">desktops</span>
<span class="w">  </span><span class="nt">vlan_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span>
</pre></div>

<p><strong>Existing Arista Config</strong></p>
<div class="code"><pre class="code literal-block">vlan<span class="w"> </span><span class="m">200</span>
<span class="w">   </span>state<span class="w"> </span><span class="nb">suspend</span>
!
</pre></div>

<p>This is how merged compares to replaced:</p>
<p><strong>merged</strong></p>
<div class="code"><pre class="code literal-block">vlan<span class="w"> </span><span class="m">200</span>
<span class="w">  </span>name<span class="w"> </span>desktops
<span class="w">  </span>state<span class="w"> </span><span class="nb">suspend</span>
!
</pre></div>

<p><strong>replaced</strong></p>
<div class="code"><pre class="code literal-block">vlan<span class="w"> </span><span class="m">200</span>
<span class="w">   </span>name<span class="w"> </span>desktops
!
</pre></div>

<p>The replaced parameter enforces the data model on the network device for
each configured VLAN.  In the example above it will remove the <code>state suspend</code>
because it is not within the data model.  To think of this
another way, the replaced parameter is aware of commands that shouldn't
be there as well as what should.</p>
<h3>Using the overridden state parameter</h3>
<p>What happens if I change the state parameter to overridden?  Just change
the original example to the following:</p>
<div class="code"><pre class="code literal-block">---
<span class="k">-</span> name: add vlans
  hosts: arista
  gather_facts: false
  tasks:
    <span class="k">-</span> name: add VLAN configuration
      eos_vlans:
        state: overridden
        config:
          <span class="k">-</span> name: desktops
            vlan_id: 20
          <span class="k">-</span> name: servers
            vlan_id: 30
          <span class="k">-</span> name: printers
            vlan_id: 40
          <span class="k">-</span> name: DMZ
            vlan_id: 50
</pre></div>

<p>Now run the Ansible Playbook:</p>
<p><img alt="screenshot" src="../images/posts/archive/sean-blog-two.png"></p>
<p>The Ansible Playbook now has changed=1.  But did it remove the
artisanal_vlan 100?</p>
<p>Logging into one of the Arista devices confirms it did!</p>
<div class="code"><pre class="code literal-block">rtr2#show<span class="w"> </span>vlan
VLAN<span class="w">  </span>Name<span class="w">                             </span>Status<span class="w">    </span>Ports
-----<span class="w"> </span>--------------------------------<span class="w"> </span>---------<span class="w"> </span>-------------------------------
<span class="m">1</span><span class="w">     </span>default<span class="w">                          </span>active
<span class="m">20</span><span class="w">    </span>desktops<span class="w">                         </span>active
<span class="m">30</span><span class="w">    </span>servers<span class="w">                          </span>active
<span class="m">40</span><span class="w">    </span>printers<span class="w">                         </span>active
<span class="m">50</span><span class="w">    </span>DMZ<span class="w">                              </span>active
</pre></div>

<p>The overridden parameter will enforce all <strong>vlans</strong> resources to the
data model.  This means it removes VLANs that are not defined in the
data model being sent.</p>
<h3>Takeaways</h3>
<p>There are currently three ways to push configuration using resource
modules.  These are the merged, replaced and overridden parameters.
These allow much more flexibility for network engineers to adopt
automation in incremental steps.  We realize that most folks will start
with the merged parameter as they gain familiarity with the new resource
module concepts. Over time organizations will move towards the
overridden parameter as they adopt a standard SoT (source of truth) for
their data models, wherever they reside.</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="agnostic-network-automation-examples-with-ansible-and-juniper-nre-labs/" class="u-url">Agnostic network automation examples with Ansible and NRE Labs</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/sean-cavanaugh/">Sean Cavanaugh</a>
              </span>
            </p>
            <p class="dateline">
              <a href="agnostic-network-automation-examples-with-ansible-and-juniper-nre-labs/" rel="bookmark">
                <time class="published dt-published" datetime="2020-02-10T00:00:00Z" itemprop="datePublished" title="2020-02-10 00:00">2020-02-10 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>Agnostic network automation examples with Ansible and NRE Labs</h2>
<p>On February 10th, The NRE Labs project launched four Ansible Network
Automation exercises, made possible by Red Hat and Juniper Networks. 
This blog post covers job responsibilities of an NRE, the goal of NRE
Labs, and a quick overview of new exercises and the concepts Red Hat and
Juniper are jointly demonstrating.  The intended audience for these
initial exercises is someone new to Ansible Network Automation with
limited experience with Ansible and network automation. The initial
network topology for these exercises covers Ansible automating Juniper
Junos OS and Cumulus VX virtual network instances.</p>
<h2>About NRE Labs</h2>
<p>Juniper has defined an NRE or <a href="https://www.juniper.net/us/en/products-services/what-is/nre/">network reliability engineer</a>,
as someone that can help an organization with modern network
automation.  This concept has many different names including DevOps for
networks, NetDevOps, or simply just network automation.  Juniper and Red
Hat realized that this skill set is new to many traditional network
engineers and worked together to create online exercises to help folks
get started with Ansible Network Automation.  Specifically, Juniper
worked with us through NRE Labs, a project they started and co-sponsor
that offers a no-strings-attached, community-centered initiative to
bring the skills of automation within reach for everyone. This works
through short, simple exercises within your browser.  You can find NRE
Labs at the following location:
<a href="https://nrelabs.io/">https://nrelabs.io</a></p>
<p>With Red Hat Ansible Engine 2.9 we introduced the concept of resource modules
and native fact gathering, so I wanted to make sure that these exercises
covered the latest and greatest aspects of Ansible Network Automation to
make this turn key for network engineers.  If you are new to resource
modules, native fact gathering or even just the Juniper network platform
I think it is worth skimming through these exercises!</p>
<p>Lets begin with a network diagram:</p>
<p><img alt="NRE diagram" src="../images/posts/archive/NRE_diagram.png"></p>
<p>Each of the four exercises has a different set of objectives outlined,
step-by-step instructions and takeaways for your Ansible knowledge.</p>
<p><a href="https://go.nrelabs.io/labs/?lessonSlug=ansible-network-automation&amp;lessonStage=0">Exercise 1</a></p>
<p>This exercise covers what an Ansible INI-based inventory looks like, the
Ansible configuration file (ansible.cfg) and running an Ansible Playbook
for enabling NETCONF on Juniper Junos.  This exercise also illustrates
the concept of idempotency and why it is important for network
automation.</p>
<p><a href="https://go.nrelabs.io/labs/?lessonSlug=ansible-network-automation&amp;lessonStage=1">Exercise 2</a> - Facts</p>
<p>This exercise covers native fact gathering (using gather_facts: True)
and using the debug module.  We show how to quickly print serial numbers
and version numbers to the terminal window using just three tasks.</p>
<p><a href="https://go.nrelabs.io/labs/?lessonSlug=ansible-network-automation&amp;lessonStage=2">Exercise 3</a> - Resource Facts</p>
<p>This exercise covers more in depth fact gathering using the junos_facts
module in conjunction with the new gather_network_resources parameter. 
This allows the junos_facts module to gather facts from any resource
module to read in network configurations and store them as YAML/JSON. 
This exercise also covers converting these facts into a structured YAML
file.</p>
<p><a href="https://go.nrelabs.io/labs/?lessonSlug=ansible-network-automation&amp;lessonStage=3">Exercise 4</a> - Network Configuration Templates</p>
<p>This exercise covers using and understanding host variables, using
simple Jinja2 templating, using the junos_config module for Juniper
Junos and the template module for Cumulus Linux.  The overarching goal
of this exercise is using Ansible Network Automation to create an OSPF
adjacency between the Cumulus VX device cvx11 and the Juniper Junos
device vqfx1.</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="how-useful-is-ansible-in-a-cloud-native-kubernetes-environment/" class="u-url">How useful is Ansible in a Cloud-Native Kubernetes Environment?</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/jeff-geerling/">Jeff Geerling</a>
              </span>
            </p>
            <p class="dateline">
              <a href="how-useful-is-ansible-in-a-cloud-native-kubernetes-environment/" rel="bookmark">
                <time class="published dt-published" datetime="2020-01-14T00:00:00Z" itemprop="datePublished" title="2020-01-14 00:00">2020-01-14 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>How useful is Ansible in a Cloud-Native Kubernetes Environment?</h2>
<p>A question I've been hearing a lot lately is "why are you still using
Ansible in your Kubernetes projects?" Followed often by "what's the
point of writing your book <a href="https://www.ansibleforkubernetes.com/">Ansible for
Kubernetes</a> when Ansible isn't
really necessary once you start using Kubernetes?"</p>
<p>I spent a little time thinking about these questions, and the motivation
behind them, and wanted to write a blog post addressing them, because it
seems a lot of people may be confused about what Kubernetes does, what
Ansible does, and why both are necessary technologies in a modern
business migrating to a cloud-native technology stack (or even a fully
cloud-native business).</p>
<p>One important caveat to mention upfront, and I quote directly from my
book:</p>
<p><em>While Ansible can do almost everything for you, it may not be the right
tool for every aspect of your infrastructure automation. Sometimes there
are other tools which may more cleanly integrate with your application
developers' workflows, or have better support from app vendors.</em></p>
<p>We should always guard against the <a href="https://en.wikipedia.org/wiki/Law_of_the_instrument">golden hammer
fallacy</a>. No single
infrastructure tool---not even the best Kubernetes-as-a-service
platform---can fill the needs of an entire business's IT operation. If
anything, we have seen an explosion of specialist tools as is evidenced
by the <a href="https://landscape.cncf.io/">CNCF landscape</a>.</p>
<p>Ansible fits into multiple areas of cloud-native infrastructure
management, but I would like to specifically highlight three areas in
this post:</p>
<p><img alt="Ansible_cloud-native-venn-diagram" src="../images/posts/archive/Ansible_cloud-native-venn-diagram.png"></p>
<p>Namely, how Ansible fits into the processes for Container Builds,
Cluster Management, and Application Lifecycles.</p>
<p>I'd especially caution against teams diving into Kubernetes head first
without a broader automation strategy. Kubernetes can't manage your
entire application lifecycle, nor can it bootstrap itself; you should
not settle for automating the inside of a Kubernetes cluster while using
manual processes to build and manage your cluster; this becomes
especially dangerous if you manage more than one cluster, as is best
practice for most environments (at least having a staging and production
cluster, or a private internal cluster and a public facing cluster).</p>
<h3>Container Build</h3>
<p>In the past decade, server management and application deployment became
more and more automated. Usually, automation became more intuitive and
maintainable, especially after the introduction of configuration
management and orchestration tools like CFEngine, Puppet, Chef, and
Ansible.</p>
<p>There's no great solution for all application deployments, though, even
with modern automation tools. Java has WAR files and the VM. Python has
virtual environments. PHP has scripts and multiple execution engines.
Ruby has ruby environments. Running operations teams who can efficiently
manage servers and deployments for five, ten, or more development stacks
(and sometimes multiple versions of each, like Java 7, Java 8, and Java
11) is a failing proposition.</p>
<p>Luckily, containerization started to solve that issue. Instead of
developers handing off source code and expecting operations to be able
to handle the intricacies of multiple environments, developers hand off
containers, which can be run by a compatible container runtime on almost
any modern server environment.</p>
<p>But in some ways, things have stagnated in the container build realm;
the Dockerfile, which was nothing more than a shell script with some
Docker-specific DSL and hacky inline commands to solve image layer size
issues, is still used in many places as the <em>de facto</em> app build script.</p>
<p><img alt="Geerling Blog 3" src="../images/posts/archive/geerling-blog-three.png"></p>
<p>How many times have you encountered an indecipherable Dockerfile like
this?</p>
<p>We can do better. Ansible can build and manage containers using
Dockerfiles, sure, but Ansible is also very good at building container
images directly---and nowadays, you don't even need to install Docker!
There are lighter-weight open source build tools like
<a href="https://buildah.io/">Buildah</a> that integrate with an Ansible container
build tool
<a href="https://github.com/ansible-community/ansible-bender">ansible-bender</a> to
build containers using more expressive and maintainable Ansible
Playbooks.</p>
<p>There are other ways to build containers, too. But I lament the fact
that many developers and sysadmins have settled on the lowest common
denominator, the Dockerfile, to build their critical infrastructure
components, when there are more expressive, maintainable, and universal
tools like Ansible which produce the same end result.</p>
<h3>Cluster Management</h3>
<p>Kubernetes Clusters don't appear out of thin air. Depending on the type
of clusters you're using, they require management for upgrades and
integrations. Cluster management can become crippling, especially if,
like most organizations, you're managing multiple clusters (multiple
production clusters, staging and QA clusters, etc.).</p>
<p>If you're running inside a private cloud, or on bare metal servers, you
will need a way to install Kubernetes and manage individual servers in
the cluster. Ansible has a proven track record of being able to
orchestrate multi-server applications, and Kubernetes itself is a
multi-server application---which happens to manage one or thousands of
other multi-server applications through containerization.</p>
<p>Projects like <a href="https://kubespray.io/">Kubespray</a> have used Ansible for
custom Kubernetes cluster builds and are compatible with dozens of
different infrastructure arrangements.</p>
<p>Even if you use a managed Kubernetes offering, like AKS, EKS, or GKE,
Ansible has modules like
<a href="https://docs.ansible.com/ansible/latest/modules/azure_rm_aks_module.html">azure_rm_aks</a>,
<a href="https://docs.ansible.com/ansible/latest/modules/aws_eks_cluster_module.html">aws_eks_cluster</a>,
and
<a href="https://docs.ansible.com/ansible/latest/modules/gcp_container_cluster_module.html">gcp_container_cluster</a>,
which manage clusters, along with thousands of other modules which
simplify and somewhat standardize cluster management among different
cloud providers.</p>
<p>Even if you don't need multi-cloud capabilities, Ansible offers useful
abstractions like managing CloudFormation template deployments on AWS
with the
<a href="https://docs.ansible.com/ansible/latest/modules/cloudformation_module.html">cloudformation</a>
module, or Terraform deployments with the
<a href="https://docs.ansible.com/ansible/latest/modules/terraform_module.html">terraform</a>
module.</p>
<p>It's extremely rare to have an application which can live entirely
within Kubernetes and not need to be coordinated with any external
resource (e.g. networking device, storage, external database service,
etc.). If you're lucky, there may be a Kubernetes Operator to help you
integrate your applications with external services, but more often
there's not. Here, too, Ansible helps by managing a Kubernetes
application along with external integrations, all in one playbook
written in cloud-native's <em>lingua franca</em>, YAML.</p>
<p>I'll repeat what I said earlier: you should not settle for automating
the inside of a Kubernetes cluster while using manual processes to build
and manage your cluster---especially if you have more than one cluster!</p>
<h3>Application Lifecycle</h3>
<p>The final area where Ansible shows great promise is in managing
applications inside of Kubernetes. Using Ansible to build operators with
the <a href="https://github.com/operator-framework/operator-sdk">Operator SDK</a>,
you can encode all your application's lifecycle management (deployment,
upgrades, backups, etc.) inside of a <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">Kubernetes
operator</a>
to be placed in any Kubernetes cluster---even if you don't use Ansible
to manage anything else in that cluster.</p>
<p>Rather than forcing developers and ops teams to learn Go or another
specialized language to maintain an operator, you can build it with YAML
and Ansible.</p>
<p>There is a lot of promise here, though there are scenarios---at least,
in the current state of the Operator SDK---where you might need to drop
back to Go for more advanced use cases. The power comes in the ability
to rely on Ansible's thousands of modules from within your running
Application operator in the cluster, and in the ease of adoption for any
kind of development team.</p>
<p>For teams who already use Ansible, it's a no-brainer to migrate their
existing Ansible knowledge, roles, modules, and playbooks into
Kubernetes management playbooks and Ansible-based operators. For teams
new to Ansible, its flexibility for all things related to IT automation
(Networking, Windows, Linux, Security, etc.) and ease of use make it an
ideal companion for cloud-native orchestration.</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="rebooting-network-devices-with-ansible/" class="u-url">Rebooting Network Devices with Ansible</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/sean-cavanaugh/">Sean Cavanaugh</a>
              </span>
            </p>
            <p class="dateline">
              <a href="rebooting-network-devices-with-ansible/" rel="bookmark">
                <time class="published dt-published" datetime="2019-12-20T00:00:00Z" itemprop="datePublished" title="2019-12-20 00:00">2019-12-20 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>Rebooting Network Devices with Ansible</h2>
<p>With the Red Hat Ansible Automation Platform release in November, we
released over 50 network resource modules to help make automating
network devices easier and more turn-key for network engineers.  In
addition to the new resource modules, Andrius also discussed fact
gathering enhancements in his blog post,
which means with every new resource module, users gain increased fact
coverage for network devices.  For this blog post I want to cover
another cool enhancement that may have gone unnoticed. This is the
ability for network devices to make use of the
<a href="https://docs.ansible.com/ansible/latest/modules/wait_for_connection_module.html">wait_for_connection</a>
module.  If you are a network engineer that has operational Ansible
Playbooks that need to reboot devices or take them offline, this module
will help you make more programmatic playbooks to handle disconnects. 
By leveraging wait_for_connection network automation playbooks can look
and behave more like playbooks for Linux or Windows hosts.</p>
<h3>Comparing wait_for and wait_for_connection</h3>
<p>There are two great modules that can wait for a condition to be met,
<a href="https://docs.ansible.com/ansible/latest/modules/wait_for_module.html">wait_for</a>
and the wait_for_connection.  I highly recommend against using the pause
module if you can get away with it, and I equate it to using a
programming equivalent of a sleep within an Ansible Playbook.  Using
either of these two wait_for modules is superior to random pauses within
your Ansible Playbook because they are a more programmatic solution that
is more adaptable to devices taking different amounts of time to
complete a task.  The other problem with the pause module is that using
prompts does not work within Ansible Tower. A much better solution for
human interaction would be to use an Ansible Tower workflow with an
<a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/workflow_templates.html#approval-nodes">approval node</a>.</p>
<p>The wait_for module can wait until a path on a filesystem exists, or
until a port is active again.  This works great for most reboot use
cases, except for when a system is not able to be logged into
immediately after the port is up.  The wait_for_connection extends the
functionality of the wait_for use case a bit further. The
wait_for_connection module will make sure that Ansible can log back into
the device and receive the appropriate prompts before finishing
completing the task. For Linux and Windows hosts it will use the ping or
win_ping module, for network devices it will make sure the
<a href="https://docs.ansible.com/ansible/latest/plugins/connection.html">connection plugin</a>
that was last used can fully connect to the device.  At the time of this
blog post this only works with the <code>network_cli</code> connection plugin.  This
means that subsequent tasks can begin operating as intended as soon as
wait_for_connection completes versus where wait_for just knows that port
is open.</p>
<h3>Dealing with prompts</h3>
<p>With networking devices when we perform operational tasks such as a
reboot, there is often a prompt to confirm that you want to take an
action.</p>
<p>For example on a Juniper vSRX device:</p>
<div class="code"><pre class="code literal-block">admin@rtr3&gt;<span class="w"> </span>request<span class="w"> </span>system<span class="w"> </span>reboot
Reboot<span class="w"> </span>the<span class="w"> </span>system<span class="w"> </span>?<span class="w"> </span><span class="o">[</span>yes,no<span class="o">]</span><span class="w"> </span><span class="o">(</span>no<span class="o">)</span>
</pre></div>

<p>The user has to confirm the reload to be able to proceed.
Something I neglected to cover on my deep dive with <code>cli_command</code> blog was that <a href="https://docs.ansible.com/ansible/latest/modules/cli_command_module.html">cli_command module</a> can handle prompts.
The <code>cli_command</code> module can even handle multiple prompts!
For this example the Cisco router had not saved its config, and we are performing a reload.
First the Cisco router will alert me that the System configuration has been modified, and ask me if I want to save this before I lose my running-configuration:</p>
<div class="code"><pre class="code literal-block">rtr1#reload

System<span class="w"> </span>configuration<span class="w"> </span>has<span class="w"> </span>been<span class="w"> </span>modified.<span class="w"> </span>Save?<span class="w"> </span><span class="o">[</span>yes/no<span class="o">]</span>:
</pre></div>

<p>After confirming <code>yes</code> or <code>no</code>, you will receive a second prompt:</p>
<div class="code"><pre class="code literal-block">Proceed<span class="w"> </span>with<span class="w"> </span>reload?<span class="w"> </span><span class="o">[</span>confirm<span class="o">]</span>
</pre></div>

<p>We need to build a task that can handle both prompts using the <code>cli_command</code> module:</p>
<div class="code"><pre class="code literal-block"><span class="nn">---</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">reboot ios device</span>
<span class="w">  </span><span class="nt">cli_command</span><span class="p">:</span>
<span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">reload</span>
<span class="w">    </span><span class="nt">prompt</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Save?</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">confirm</span>
<span class="w">    </span><span class="nt">answer</span><span class="p">:</span>
<span class="w">     </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">y</span>
<span class="w">     </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">y</span>
</pre></div>

<p>The above task will answer yes to both prompts, saving the config and reloading the device.
The list for prompt answer and the list for answer must match and be in the same order.
This means that the answer for <code>prompt[0]</code> must be <code>answer[0]</code>.</p>
<p>If you want to see a more detailed example of handling multiple prompts,
<a href="https://github.com/ansible/workshops/blob/master/provisioner/roles/configure_routers/tasks/juniper_default.yml">here is an example of a password reset on a Juniper vSRX device</a>.</p>
<h3>Using reset_connection in combination</h3>
<p>Now that you understand how to reboot the device with cli_command we can combine that with the wait_for_connection to create a reusable Ansible Playbook.
However, we need to add one more task, a <a href="https://docs.ansible.com/ansible/latest/modules/meta_module.html">meta: reset_connection</a> to make this work programmatically.  </p>
<p>We need to make sure the current connection to the network device is
closed so that the socket can be reestablished to the network device
after the reboot takes place.  If the connection is not closed and the
command timeout is longer than the time it takes to reboot, the
persistent connection will attempt to reuse the closed SSH connection
resulting in the failure "Socket is closed". A correct Ansible Playbook
looks like this:</p>
<div class="code"><pre class="code literal-block"><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">reboot task (this is a snippet, full task removed for brevity)</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">reset the connection</span>
<span class="w">  </span><span class="nt">meta</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">reset_connection</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Wait for the network device to reload</span>
<span class="w">  </span><span class="nt">wait_for_connection</span><span class="p">:</span>
<span class="w">    </span><span class="nt">delay</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span>
</pre></div>

<p>Now we have an Ansible Playbook that can reconnect to network devices after a reboot is issued!
For a full example please <a href="https://gist.github.com/IPvSean/56f6522cc73629984d3e47013240a1fa">refer to this reboot.yml</a> Ansible Playbook for Arista vEOS network devices.</p>
<h3>Where to go next?</h3>
<p>This blog helped outline how to create reusable Ansible Playbooks for
rebooting network devices.  One of the next steps is obviously building
out an Ansible Role that can reboot multiple network platforms.  I have
gone ahead and <a href="https://github.com/network-automation/tower_workshop/blob/master/network_reload.yml">created one and uploaded it to Github here</a>. 
This role will work on Juniper Junos, Cisco IOS and Arista EOS devices
and can be easily modified to handle many more network operating systems.</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="getting-started-with-ansible-collections/" class="u-url">Getting Started With Ansible Content Collections</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/colin-mcnaughton/">Colin McNaughton</a>
              </span>
            </p>
            <p class="dateline">
              <a href="getting-started-with-ansible-collections/" rel="bookmark">
                <time class="published dt-published" datetime="2019-11-14T00:00:00Z" itemprop="datePublished" title="2019-11-14 00:00">2019-11-14 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>Getting Started With Ansible Content Collections</h2>
<p>With the release of Red Hat Ansible Automation Platform, Ansible Content
Collections are now fully supported. Ansible Content Collections, or
collections, represent the new standard of distributing, maintaining and
consuming automation. By combining multiple types of Ansible content
(playbooks, roles, modules, and plugins), flexibility and scalability
are greatly improved.</p>
<h3>Who Benefits?</h3>
<p><strong>Everyone!</strong></p>
<p>Traditionally, module creators have had to wait for their modules to be
marked for inclusion in an upcoming Ansible release or had to add them
to roles, which made consumption and management more difficult. By
shipping modules within Ansible Content Collections along with pertinent
roles and documentation, and removing the barrier to entry, creators are
now able to move as fast as the demand for their creations. For a public
cloud provider, this means new functionality of an existing service or a
new service altogether, can be rolled out along with the ability to
automate the new functionality.</p>
<p>For the automation consumer, this means that fresh content is
continuously made available for consumption. Managing content in this
manner also becomes easier as modules, plugins, roles, and docs are
packaged and tagged with a collection version. Modules can be updated,
renamed, improved upon; roles can be updated to reflect changes in
module interaction; docs can be regenerated to reflect the edits and all
are packaged and tagged together. </p>
<p>On top of this, before collections, it was not uncommon for modules to
break or lack timely updates needed to interact with the services they
were interfacing with. This often required Ansible users or Ansible
Tower administrators to run multiple versions of Ansible in <a href="https://docs.ansible.com/ansible-tower/latest/html/administration/tipsandtricks.html#using-virtualenv-with-at">virtual
environments</a>
in order to consume a patch that addressed a module issue. Ansible
Content Collections bring stability and predictability by breaking
modules out from the core distribution.</p>
<p>For automated organizations, this means that certified content is
readily available to be applied to use-cases ripe for automation from
day one.</p>
<h3>Where to Find Collections</h3>
<p>With the launch of Red Hat Ansible Automation Platform, Automation Hub
will be the source for certified collections. Additionally, collections
creators can also package and distribute content on Ansible Galaxy.
Ultimately, it is up to the creator to decide the delivery mechanism for
their content, with Automation Hub being the only source for Red Hat
Certified Collections.</p>
<h3>A Closer Look at Collections</h3>
<p>An Ansible Content Collection can be described as a package format for
Ansible content:</p>
<p><img alt="example collection filesystem" src="../images/posts/archive/example-collection-filesystem.png"></p>
<p>This format has a simple, predictable data structure, with a
straightforward definition:</p>
<ul>
<li>
<code>docs/</code>: local documentation for the collection</li>
<li>
<code>galaxy.yml</code>: source data for the MANIFEST.json that will be part of
    the collection package</li>
<li>
<code>playbooks/</code>: playbooks reside here <ul>
<li>
<code>tasks/</code>: this holds 'task list files' for <code>include_tasks/import_tasks</code> usage</li>
</ul>
</li>
<li>
<code>plugins/</code>: all ansible plugins and modules go here, each in its own subdir<ul>
<li>
<code>modules/</code>: ansible modules</li>
<li>
<code>lookups/</code>: <a href="https://docs.ansible.com/ansible/latest/plugins/lookup.html">lookup plugins</a>
</li>
<li>
<code>filters/</code>: <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html">Jinja2 filter plugins</a>
</li>
<li>
<code>connection/</code>: <a href="https://docs.ansible.com/ansible/latest/plugins/connection.html">connection plugins</a>
    required if not using default</li>
</ul>
</li>
<li>
<code>roles/</code>: directory for ansible roles</li>
<li>
<code>tests/</code>: tests for the collection's content</li>
</ul>
<p><a href="https://docs.ansible.com/ansible/latest/dev_guide/collections_galaxy_meta.html">More information regarding collection
metadata</a></p>
<h3>Interacting with Collections</h3>
<p>In addition to downloading collections through the browser, the
<code>ansible-galaxy</code> command line utility has been updated to manage
collections, providing much of the same functionality as has always been
present to manage, create and consume roles. For example,
<code>ansible-galaxy collection init</code> can be used to create a starting
point for a new user created collection.</p>
<p><img alt="galaxy collection init example" src="../images/posts/archive/init-galaxy-collection.gif"></p>
<p>Along with the correct directory structure to start creating a
collection from, this command also generates a metadata file that will
be used while building the collection with namespace and collection name
pre-populated:</p>
<p><img alt="example galaxy metadata" src="../images/posts/archive/example-collection-galaxy.png"></p>
<h3>Where to Go Next</h3>
<p>Ansible Content Collections were first introduced as tech preview in
Ansible Engine 2.8 and are now fully supported in Ansible Engine 2.9 and
are an integral part of Red Hat Ansible Automation Platform. Collections
allow Red Hat Ansible Automation Platform to offer certified, stable
content in order to continue expanding use cases for automation. Future
posts will dive deeper into developing new collections and converting
existing roles into collections.</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="ansible-servicenow-howto-part-3-making-outbound-restful-api-calls-to-ansible-tower/" class="u-url">Ansible and ServiceNow Part 3, Making outbound RESTful API calls to Red Hat Ansible Tower</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/michael-ford/">Michael Ford</a>
              </span>
            </p>
            <p class="dateline">
              <a href="ansible-servicenow-howto-part-3-making-outbound-restful-api-calls-to-ansible-tower/" rel="bookmark">
                <time class="published dt-published" datetime="2019-10-09T00:00:00Z" itemprop="datePublished" title="2019-10-09 00:00">2019-10-09 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>Ansible and ServiceNow Part 3, Making outbound RESTful API calls to Red Hat Ansible Tower</h2>
<p>Red Hat Ansible Tower offers value by allowing automation to scale in a
checked manner - users can run playbooks for only the processes and
targets they need access to, and no further. </p>
<p>Not only does Ansible Tower provide automation at scale, but it also
integrates with several external platforms. In many cases, this means
that users can use the interface they are accustomed to while launching
Ansible Tower templates in the background. </p>
<p>One of the most ubiquitous self service platforms in use today is
ServiceNow, and many of the enterprise conversations had with Ansible
Tower customers focus on ServiceNow integration. With this in mind, this
blog entry walks through the steps to set up your ServiceNow instance to
make outbound RESTful API calls into Ansible Tower, using OAuth2
authentication.</p>
<p>The following software versions are used:</p>
<ul>
<li>Ansible Tower: 3.4, 3.5</li>
<li>ServiceNow: London, Madrid</li>
</ul>
<p>If you sign up for a ServiceNow Developer account, ServiceNow offers a
free instance that can be used for replicating and testing this
functionality. Your ServiceNow instance needs to be able to reach your
Ansible Tower instance. Additionally, you can visit
<a href="https://ansible.com/license">https://ansible.com/license</a> to obtain a trial license for Ansible
Tower. Instructions for installing Ansible Tower can be found
<a href="https://docs.ansible.com/ansible-tower/latest/html/quickinstall/prepare.html">here</a>. </p>
<h3>Preparing Ansible Tower</h3>
<ol>
<li>
<p>In Ansible Tower, navigate to <strong>Applications</strong> on the left side of
the screen. Click the <strong>green plus button</strong> on the right, which will
present you with a Create Application dialog screen. Fill in the
following fields:</p>
</li>
<li>
<p>Name: Descriptive name of the application that will contact Ansible Tower</p>
</li>
<li>Organization: The organization you wish this application to be a part of</li>
<li>Authorization Grant Type: Authorization code</li>
<li>Redirect URIS: <code>https://&lt;snow_instance_id&gt;.service-now.com/oauth_redirect.do</code>
</li>
<li>
<p>Client Type: Confidential</p>
<p><img alt="image3-4" src="../images/posts/archive/image3-4.png"></p>
</li>
<li>
<p>Click the green <strong>Save</strong> button on the right, at which point a
window will pop up, presenting you with the Client ID and Client Secret
needed for ServiceNow to make API calls into Ansible Tower. This will
only be presented <strong>ONCE</strong>, so capture these values for later use.</p>
<p><img alt="image18" src="../images/posts/archive/image18.png"></p>
</li>
<li>
<p>Next, navigate to <strong>Settings-&gt;System</strong> on the left side of the
screen. You'll want to toggle the <strong>Allow External Users to Create
Oauth2 Tokens</strong> option to <strong>on</strong>. Click the green <strong>Save</strong> button to commit the change.</p>
<p><img alt="image4-4" src="../images/posts/archive/image4-4.png"></p>
</li>
</ol>
<h3>Preparing ServiceNow</h3>
<ol>
<li>
<p>Moving over to ServiceNow, Navigate to <strong>System Definition-&gt;Certificates</strong>.
This will take you to a screen of all the
certificates Service Now uses. Click on the <strong>blue New button</strong>, and
fill in these details:</p>
</li>
<li>
<p>Name: Descriptive name of the certificate</p>
</li>
<li>Format: PEM</li>
<li>Type: Trust Store Cert</li>
<li>
<p>PEM Certificate: The certificate to authenticate against Ansible
    Tower with. You can use the built-in certificate on your Tower
    server, located at <code>/etc/tower/tower.cert</code>. Copy the contents of this
    file into the field in ServiceNow.</p>
<p>Click the <strong>Submit</strong> button at the bottom.</p>
<p><img alt="image9-1" src="../images/posts/archive/image9-1.png"></p>
</li>
<li>
<p>In ServiceNow, Navigate to <strong>System OAuth-&gt;Application Registry</strong>.
This will take you to a screen of all the Applications ServiceNow
communicates with. Click on the <strong>blue New button</strong>, and you will be
asked What kind of Oauth application you want to set up. Select
<strong>Connect to a third party Oauth Provider</strong>.</p>
<p><img alt="image20" src="../images/posts/archive/image20.png"></p>
</li>
<li>
<p>On the new application screen, fill in these details:</p>
</li>
<li>
<p>Name: Descriptive Application Name</p>
</li>
<li>Client ID: The Client ID you got from Ansible Tower</li>
<li>Client Secret: The Client Secret you got from Ansible Tower</li>
<li>Default Grant Type: Authorization Code</li>
<li>Authorization URL: <code>https://&lt;tower_url&gt;/api/o/authorize/</code>
</li>
<li>Token URL: <code>https://&lt;tower_url&gt;/api/o/token/</code>
</li>
<li>
<p>Redirect URL: <code>https://&lt;snow_instance_id&gt;.service-now.com/oauth_redirect.do</code></p>
<p>Click the <strong>Submit</strong> button at the bottom.</p>
<p><img alt="image19" src="../images/posts/archive/image19.png"></p>
</li>
<li>
<p>You should be taken out to the list of all Application Registries.
Click back into the Application you just created. At the bottom, there
should be two tabs: Click on the tab <strong>Oauth Entity Scopes</strong>. Under
here, there is a section called <strong>Insert a new row...</strong>. Double click
here, and fill in the field to say Writing Scope. Click on the <strong>green
check mark</strong> to confirm this change. Then, right-click inside the grey
area at the top where it says Application Registries and click Save in
the menu that pops up.</p>
<p><img alt="image11-1" src="../images/posts/archive/image11-1.png"></p>
</li>
<li>
<p>The writing scope should now be Clickable. Click on it, and in the
dialog window that you are taken to, type <strong>write</strong> in the Oauth scope
box. Click the Update button at the bottom.</p>
<p><img alt="image7-1" src="../images/posts/archive/image7-1.png"></p>
</li>
<li>
<p>Back in the Application Settings page, scroll back to the bottom and
click the <strong>Oauth Entity Profiles</strong> tab. There should be an entity
profile populated - click into it.</p>
<p><img alt="image21" src="../images/posts/archive/image21.png"></p>
</li>
<li>
<p>You will be taken to the Oauth Entity Profile Window. At the
bottom, Type <strong>Writing Scope</strong> into the Oauth Entity Scope field. Click
the green check mark and update.</p>
<p><img alt="image23" src="../images/posts/archive/image23.png"></p>
</li>
<li>
<p>Navigate to <strong>System Web Services -&gt; REST Messages</strong>. Click the
blue <strong>New</strong> button. In the resulting dialog window, fill in the
following fields:</p>
</li>
<li>
<p>Name: Descriptive REST Message Name</p>
</li>
<li>Endpoint: The url endpoint of the Ansible Tower action you wish to
    do. This can be taken from the browsable API at
    <code>https://&lt;tower_url&gt;/api</code>
</li>
<li>Authentication Type: Oauth 2.0</li>
<li>
<p>Oauth Profile: Select the Oauth profile you created</p>
<p>Right-click inside the grey area at the top; click <strong>Save</strong>.</p>
<p><img alt="image10-1" src="../images/posts/archive/image10-1.png"></p>
</li>
<li>
<p>Click the <strong>Get Oauth Token</strong> button on the REST Message screen.
This will generate a pop-up window asking to authorize ServiceNow
against your Ansible Tower instance/cluster. Click Authorize. ServiceNow will now have an OAuth2 token to authenticate against your Ansible Tower server.</p>
<p><img alt="image22" src="../images/posts/archive/image22.png"></p>
</li>
<li>
<p>Under the HTTP Methods section at the bottom, click the blue New button. At the new dialog window that appears, fill in the following fields:</p>
</li>
<li>
<p>HTTP Method: POST</p>
</li>
<li>Name: Descriptive HTTP Method Name</li>
<li>Endpoint: The url endpoint of the Ansible Tower action you wish to do. This can be taken from the browsable API at
    <code>https://&lt;tower_url&gt;/api</code>
</li>
<li>HTTP Headers (under the HTTP Request tab)<ul>
<li>The only HTTP Header that should be required is <em>Content-Type: application/json</em>
</li>
</ul>
</li>
</ol>
<p>You can kick off a RESTful call to Ansible Tower using these parameters
with the <strong>Test</strong> link.</p>
<p><img alt="image6-3" src="../images/posts/archive/image6-3.png"></p>
<h3>Testing connectivity between ServiceNow and Ansible Tower</h3>
<p>Clicking the <strong>Test</strong> link will take you to a results screen, which
should indicate that the Restful call was sent successfully to Ansible
Tower. In this example, ServiceNow kicks off an Ansible Tower job
Template, and the response includes the Job ID in Ansible Tower: 276.</p>
<p><img alt="image eight" src="../images/posts/archive/image-88.png"></p>
<p>You can confirm that this Job Template was in fact started by going back
to Ansible Tower and clicking the <strong>Jobs</strong> section on the left side of
the screen; a Job with the same ID should be in the list (and, depending
on the playbook size, may still be in process):</p>
<p><img alt="image15" src="../images/posts/archive/image15.png"></p>
<h3>Creating a ServiceNow Catalog Item to Launch an Ansible Tower Job Template</h3>
<p>Now that you are able to make outbound RESTful calls from
ServiceNow to Ansible Tower, it's time to create a catalog item for
users to select in ServiceNow in a production self-service fashion.
While in the HTTP Method options, click the <strong>Preview Script Usage</strong>
link:</p>
<p><img alt="image nine" src="../images/posts/archive/image-99.png"></p>
<p>Copy the resulting script the appears, and paste it into a text editor
to reference later.</p>
<ol>
<li>
<p>In ServiceNow, navigate to <strong>Workflow -&gt; Workflow Editor.</strong> This
will open a new tab with a list of all existing ServiceNow workflows.
Click on the blue <strong>New Workflow</strong> button:</p>
<p><img alt="image16" src="../images/posts/archive/image16.png"></p>
</li>
<li>
<p>In the <strong>New Workflow</strong> dialog box that appears, fill in the
following options:</p>
</li>
<li>
<p>Name: A descriptive name of the workflow</p>
</li>
<li>
<p>Table: Requested Item <code>sc_req_item</code></p>
<p>Everything else can be left alone. Click the <strong>Submit</strong> button.</p>
<p><img alt="image1-10" src="../images/posts/archive/image1-10.png"></p>
</li>
<li>
<p>The resulting Workflow Editor will have only a Begin and End box.
Click on the line (it will turn blue to indicate it has been selected),
then press delete to get rid of it.</p>
<p><img alt="image14-1" src="../images/posts/archive/image14-1.png"></p>
</li>
<li>
<p>On the right side of the Workflow Editor Screen, select the Core
tab and, under Core Activities-&gt;Utilities, drag the Run Script option
into the Workflow Editor. In the new dialog box that appears, type in a
descriptive name, and paste in the script you captured from before.
Click Submit to save the Script.</p>
<p><img alt="image12-1" src="../images/posts/archive/image12-1.png"></p>
</li>
<li>
<p>Draw a connection from <strong>Begin</strong>, to the newly created Run Script
Box, and another from the <strong>Run Script</strong> box to <strong>End</strong>. Afterward,
click on the three horizontal lines to the left of the Workflow name,
and select the <strong>Publish</strong> option. You are now ready to associate this
workflow with a catalog item.</p>
<p><img alt="image8-1" src="../images/posts/archive/image8-1.png"></p>
</li>
<li>
<p>Navigate to <strong>Service Catalog -&gt; Catalog Definitions -&gt; Maintain Items</strong>. Click the blue <strong>New</strong> button on the resulting item list. In
the resulting dialog box, fill in the following fields:</p>
</li>
<li>
<p>Name: Descriptive name of the Catalog Item</p>
</li>
<li>Catalog: The catalog that this item should be a part of</li>
<li>
<p>Category: Required if you wish users to be able to search for this
    item</p>
<p>In the Process Engine tab, populate the <strong>Workflow</strong> field with the Workflow you just created.
Click the Submit Button.
You've not created a new catalog item!</p>
<p><img alt="image5-4" src="../images/posts/archive/image5-4.png"></p>
</li>
<li>
<p>Lastly, to run this catalog item, navigate to
<strong>Self-Service -&gt; Homepage</strong> and search for the catalog item you just
created. Once found, click the <strong>order now</strong> button. You can see the
results page pop up in ServiceNow, and you can confirm that the Job is
being run in Ansible Tower.</p>
</li>
</ol>
<p>Congratulations! After completing these steps, you can now use a
ServiceNow Catalog Item to launch Job and Workflow Templates in Ansible
Tower. This is ideal for allowing end users to use a front end they are
familiar with in order to perform automated tasks of varying
complexities. This familiarity goes a long way toward reducing the time
to value for the enterprise as a whole, rather than just the teams
responsible for writing the playbooks being used.</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="kubernetes-operators-ansible-deep-dive-part-2/" class="u-url">Kubernetes Operators with Ansible Deep Dive, Part 2</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/james-cammarata/">James Cammarata</a>
              </span>
            </p>
            <p class="dateline">
              <a href="kubernetes-operators-ansible-deep-dive-part-2/" rel="bookmark">
                <time class="published dt-published" datetime="2019-08-01T00:00:00Z" itemprop="datePublished" title="2019-08-01 00:00">2019-08-01 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>Kubernetes Operators with Ansible Deep Dive, Part 2</h2>
<p>In part 1 of this series, we looked at operators overall, and what they do in
OpenShift/Kubernetes. We peeked at the Operator SDK, and why you'd want
to use an Ansible Operator rather than other kinds of operators provided
by the SDK. We also explored how Ansible Operators are structured and
the relevant files created by the Operator SDK when building Kubernetes
Operators with Ansible.</p>
<p>In this the second part of this deep dive series, we'll:</p>
<ol>
<li>Take a look at creating an OpenShift Project and deploying a Galera Operator.</li>
<li>Next we'll check the MySQL cluster, then setup and test a Galera cluster.</li>
<li>Then we'll test scaling down, disaster recovery, and demonstrate cleaning up.</li>
</ol>
<h3>Creating the project and deploying the operator</h3>
<p>We start by creating a new project in OpenShift, which we'll simply call <code>test</code>:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>new-project<span class="w"> </span><span class="nb">test</span><span class="w"> </span>--display-name<span class="o">=</span><span class="s2">"Testing Ansible Operator"</span>
Now<span class="w"> </span>using<span class="w"> </span>project<span class="w"> </span><span class="s2">"test"</span><span class="w"> </span>on<span class="w"> </span>server<span class="w"> </span><span class="s2">"https://ec2-xx-yy-zz-1.us-east-2.compute.amazonaws.com:8443"</span>
</pre></div>

<p>We won't delve too much into this role, however the basic operation is:</p>
<ol>
<li>Use <code>set_fact</code> to generate variables using the <code>k8s</code> lookup plugin or other variables defined in <code>defaults/main.yml</code>.</li>
<li>Determine if any corrective action needs to be taken based on the above variables.
    For example, one variable determines how many Galera node pods are currently running.
    This is compared against the variable defined on the <code>CustomResource</code>.
    If they differ, the role will add or remove pods as needed.</li>
</ol>
<p>To begin the deployment, we have a simple script, which builds the operator image and pushes it to the OpenShift registry for
the <code>test</code> project:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>cat<span class="w"> </span>./create_operator.sh
<span class="c1">#!/bin/bash</span>

docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>docker-registry-default.router.default.svc.cluster.local/test/galera-ansible-operator:latest<span class="w"> </span>.
docker<span class="w"> </span>push<span class="w"> </span>docker-registry-default.router.default.svc.cluster.local/test/galera-ansible-operator:latest
kubectl<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>deploy/operator.yaml
kubectl<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml
</pre></div>

<p>Before we run this script, we need to first deploy the RBAC rules and
custom resource definition for our Galera example:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>deploy/rbac.yaml
clusterrole<span class="w"> </span><span class="s2">"galera-ansible-operator"</span><span class="w"> </span>created
clusterrolebinding<span class="w"> </span><span class="s2">"default-account-app-operator"</span><span class="w"> </span>created
$<span class="w"> </span>oc<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>deploy/crd.yaml
customresourcedefinition<span class="w"> </span><span class="s2">"galeraservices.galera.database.coreos.com"</span><span class="w"> </span>created
</pre></div>

<p>Now, we run the script (after using the login command to allow docker to
connect to the OpenShift registry we created):</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>docker<span class="w"> </span>login<span class="w"> </span>-p<span class="w"> </span><span class="k">$(</span>oc<span class="w"> </span>whoami<span class="w"> </span>-t<span class="k">)</span><span class="w"> </span>-u<span class="w"> </span>unused<span class="w"> </span>docker-registry-default.router.default.svc.cluster.local
Login<span class="w"> </span>Succeeded

$<span class="w"> </span>./create_operator.sh
Sending<span class="w"> </span>build<span class="w"> </span>context<span class="w"> </span>to<span class="w"> </span>Docker<span class="w"> </span>daemon<span class="w"> </span><span class="m">490</span><span class="w"> </span>kB
...
deployment.apps/galera-ansible-operator<span class="w"> </span>created
galeraservice<span class="w"> </span><span class="s2">"galera-example"</span><span class="w"> </span>created
</pre></div>

<p>In short order, we will see the galera-ansible-operator pod start up,
followed by a single pod named galera-node-0001 and a LoadBalancer
service which provides our ingress to our Galera cluster:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>all
NAME<span class="w"> </span>DOCKER<span class="w"> </span>REPO<span class="w"> </span>TAGS<span class="w"> </span>UPDATED
is/galera-ansible-operator<span class="w"> </span>docker-registry-default.router...:5000/test/galera-ansible-operator<span class="w"> </span>latest<span class="w"> </span><span class="m">3</span><span class="w"> </span>hours<span class="w"> </span>ago

NAME<span class="w"> </span>DESIRED<span class="w"> </span>CURRENT<span class="w"> </span>UP-TO-DATE<span class="w"> </span>AVAILABLE<span class="w"> </span>AGE
deploy/galera-ansible-operator<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>4m

NAME<span class="w"> </span>CLUSTER-IP<span class="w"> </span>EXTERNAL-IP<span class="w"> </span>PORT<span class="o">(</span>S<span class="o">)</span><span class="w"> </span>AGE
svc/galera-external-loadbalancer<span class="w"> </span><span class="m">172</span>.30.251.195<span class="w"> </span><span class="m">172</span>.29.17.210,172.29.17.210<span class="w"> </span><span class="m">33066</span>:30072/TCP<span class="w"> </span>1m
svc/glusterfs-dynamic-galera-node-0001-mysql-data<span class="w"> </span><span class="m">172</span>.30.49.250<span class="w"> </span>&lt;none&gt;<span class="w"> </span><span class="m">1</span>/TCP<span class="w"> </span>1m

NAME<span class="w"> </span>DESIRED<span class="w"> </span>CURRENT<span class="w"> </span>READY<span class="w"> </span>AGE
rs/galera-ansible-operator-bc6cd548<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>4m

NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
po/galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>4m
po/galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>1m
</pre></div>

<p>Verifying the MySQL cluster, initial setup and testing</p>
<p>We can use the describe function to see the status of our custom
resource, specifically the size we specified:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>kubectl<span class="w"> </span>describe<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml<span class="w"> </span><span class="p">|</span>grep<span class="w"> </span>-i<span class="w"> </span>size
Galera<span class="w"> </span>_<span class="w"> </span>Cluster<span class="w"> </span>_<span class="w"> </span>Size:<span class="w"> </span><span class="m">1</span>
</pre></div>

<p>Now that we have a MySQL cluster, let's test it using
<a href="https://github.com/akopytov/sysbench">sysbench</a>.
As mentioned above, we have a system from which to do the testing so we
can avoid internet round trips. But first, we'll need some info. We
need to know the forwarded port we can connect to through the load
balancing service created as part of the operator deployment:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>services
</pre></div>

<p>Next, we need to know the IP of the master. We can get this with <code>oc describe</code>:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>describe<span class="w"> </span>node<span class="w"> </span>ec2-xx-yy-zz-1.us-east-2.compute.amazonaws.com<span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>^Addresses
Addresses:<span class="w"> </span><span class="m">10</span>.0.0.46,ec2-xx-yy-zz-1.us-east-2.compute.amazonaws.com
</pre></div>

<p>So for this test, we'll be connecting to the IP 10.0.0.46 on port
XXXXX. The port value 33066 was specified in the spec above, and is the
port which will receive the forwarded traffic. We'll export those to
make it a little easier to re-use our test commands.</p>
<p>From the test server:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">MYSQL_IP</span><span class="o">=</span><span class="m">10</span>.0.0.46
$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">MYSQL_PORT</span><span class="o">=</span>XXXXX
</pre></div>

<p>Before running sysbench, we need to create the database it expects
(future versions of the Galera operator will be able to do this
automatically):</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>mysql<span class="w"> </span>-h<span class="w"> </span><span class="nv">$MYSQL_IP</span><span class="w"> </span>--port<span class="o">=</span><span class="nv">$MYSQL_PORT</span><span class="w"> </span>-u<span class="w"> </span>root<span class="w"> </span>-e<span class="w"> </span><span class="s1">'create database sbtest;'</span>
</pre></div>

<p>Next, we'll prepare the test by running sysbench using the OLTP
read-only test with a table of 1 million rows:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>sysbench<span class="w"> </span>--db-driver<span class="o">=</span>mysql<span class="w"> </span>--threads<span class="o">=</span><span class="m">150</span><span class="w"> </span>--mysql-host<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_IP</span><span class="si">}</span><span class="w"> </span>--mysql-port<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_PORT</span><span class="si">}</span><span class="w"> </span>--mysql-user<span class="o">=</span>root<span class="w"> </span>--mysql-password<span class="o">=</span><span class="w"> </span>--mysql-ignore-errors<span class="o">=</span>all<span class="w"> </span>--table-size<span class="o">=</span><span class="m">1000000</span><span class="w"> </span>/usr/share/sysbench/oltp_read_only.lua<span class="w"> </span>prepare
sysbench<span class="w"> </span><span class="m">1</span>.0.9<span class="w"> </span><span class="o">(</span>using<span class="w"> </span>system<span class="w"> </span>LuaJIT<span class="w"> </span><span class="m">2</span>.0.4<span class="o">)</span>
Initializing<span class="w"> </span>worker<span class="w"> </span>threads...
Creating<span class="w"> </span>table<span class="w"> </span><span class="s1">'sbtest1'</span>...
Inserting<span class="w"> </span><span class="m">1000000</span><span class="w"> </span>records<span class="w"> </span>into<span class="w"> </span><span class="s1">'sbtest1'</span>
Creating<span class="w"> </span>a<span class="w"> </span>secondary<span class="w"> </span>index<span class="w"> </span>on<span class="w"> </span><span class="s1">'sbtest1'</span>

...
</pre></div>

<p>Note that we use 150 threads here, as a single MySQL/MariaDB instance
defaults to this size for its maximum connections allowed.</p>
<p>So now that everything's ready, lets run our first test with sysbench:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>sysbench<span class="w"> </span>--db-driver<span class="o">=</span>mysql<span class="w"> </span>--threads<span class="o">=</span><span class="m">150</span><span class="w"> </span>--mysql-host<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_IP</span><span class="si">}</span><span class="w"> </span>--mysql-port<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_PORT</span><span class="si">}</span><span class="w"> </span>--mysql-user<span class="o">=</span>root<span class="w"> </span>--mysql-password<span class="o">=</span><span class="w"> </span>--mysql-ignore-errors<span class="o">=</span>all<span class="w"> </span>/usr/share/sysbench/oltp_read_only.lua<span class="w"> </span>run
sysbench<span class="w"> </span><span class="m">1</span>.0.9<span class="w"> </span><span class="o">(</span>using<span class="w"> </span>system<span class="w"> </span>LuaJIT<span class="w"> </span><span class="m">2</span>.0.4<span class="o">)</span>
Running<span class="w"> </span>the<span class="w"> </span><span class="nb">test</span><span class="w"> </span>with<span class="w"> </span>following<span class="w"> </span>options:
Number<span class="w"> </span>of<span class="w"> </span>threads:<span class="w"> </span><span class="m">150</span>
Initializing<span class="w"> </span>random<span class="w"> </span>number<span class="w"> </span>generator<span class="w"> </span>from<span class="w"> </span>current<span class="w"> </span><span class="nb">time</span>
Initializing<span class="w"> </span>worker<span class="w"> </span>threads...
Threads<span class="w"> </span>started!
SQL<span class="w"> </span>statistics:
<span class="w">    </span>queries<span class="w"> </span>performed:
<span class="w">        </span>read:<span class="w">                            </span><span class="m">174776</span>
<span class="w">        </span>write:<span class="w">                           </span><span class="m">0</span>
<span class="w">        </span>other:<span class="w">                           </span><span class="m">24968</span>
<span class="w">        </span>total:<span class="w">                           </span><span class="m">199744</span>
<span class="w">    </span>transactions:<span class="w">                        </span><span class="m">12484</span><span class="w">  </span><span class="o">(</span><span class="m">1239</span>.55<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>queries:<span class="w">                             </span><span class="m">199744</span><span class="w"> </span><span class="o">(</span><span class="m">19832</span>.77<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>ignored<span class="w"> </span>errors:<span class="w">                      </span><span class="m">0</span><span class="w">      </span><span class="o">(</span><span class="m">0</span>.00<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>reconnects:<span class="w">                          </span><span class="m">0</span><span class="w">      </span><span class="o">(</span><span class="m">0</span>.00<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
General<span class="w"> </span>statistics:
<span class="w">    </span>total<span class="w"> </span>time:<span class="w">                          </span><span class="m">10</span>.0700s
<span class="w">    </span>total<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>events:<span class="w">              </span><span class="m">12484</span>
Latency<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:
<span class="w">         </span>min:<span class="w">                                  </span><span class="m">3</span>.82
<span class="w">         </span>avg:<span class="w">                                </span><span class="m">120</span>.66
<span class="w">         </span>max:<span class="w">                               </span><span class="m">1028</span>.51
<span class="w">         </span>95th<span class="w"> </span>percentile:<span class="w">                    </span><span class="m">292</span>.60
<span class="w">         </span>sum:<span class="w">                            </span><span class="m">1506263</span>.71
Threads<span class="w"> </span>fairness:
<span class="w">    </span>events<span class="w"> </span><span class="o">(</span>avg/stddev<span class="o">)</span>:<span class="w">           </span><span class="m">83</span>.2267/42.84
<span class="w">    </span>execution<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>avg/stddev<span class="o">)</span>:<span class="w">   </span><span class="m">10</span>.0418/0.02
</pre></div>

<p>This was just one run, but re-running a few times produces similar
results. So our one-node cluster can process about 20K queries/second.
But a cluster with only one member isn't very useful - so lets scale it
up. We do this by editing the custom resource we defined earlier and
changing the <code>galera_cluster_size</code> variable.
For now, we'll spin up to a three-node cluster:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>edit<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml
galeraservice.galera.database.coreos.com/galera-example<span class="w"> </span>edited
</pre></div>

<p>Next, we can verify OpenShift sees this new value:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>kubectl<span class="w"> </span>describe<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-i<span class="w"> </span>size
Galera<span class="w"> </span>_<span class="w"> </span>Cluster<span class="w"> </span>_<span class="w"> </span>Size:<span class="w"> </span><span class="m">3</span>
</pre></div>

<p>And in short order, we see the Ansible operator receive an event
signalling the change and start working to update the cluster:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>pods
NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>30m
galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>26m
galera-node-0002<span class="w"> </span><span class="m">0</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>1m
galera-node-0003<span class="w"> </span><span class="m">0</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>56s
</pre></div>

<p>And after about a minute (each Galera node has to start and sync data from another member), we see the new pods become ready:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>pods
NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>31m
galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>27m
galera-node-0002<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>2m
galera-node-0003<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>2m
</pre></div>

<p>Now that we have a three node cluster, we can re-run the same test as earlier:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>sysbench<span class="w"> </span>--db-driver<span class="o">=</span>mysql<span class="w"> </span>--threads<span class="o">=</span><span class="m">150</span><span class="w"> </span>--mysql-host<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_IP</span><span class="si">}</span><span class="w"> </span>--mysql-port<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_PORT</span><span class="si">}</span><span class="w"> </span>--mysql-user<span class="o">=</span>root<span class="w"> </span>--mysql-password<span class="o">=</span><span class="w"> </span>--mysql-ignore-errors<span class="o">=</span>all<span class="w"> </span>/usr/share/sysbench/oltp_read_only.lua<span class="w"> </span>run
sysbench<span class="w"> </span><span class="m">1</span>.0.9<span class="w"> </span><span class="o">(</span>using<span class="w"> </span>system<span class="w"> </span>LuaJIT<span class="w"> </span><span class="m">2</span>.0.4<span class="o">)</span>
Running<span class="w"> </span>the<span class="w"> </span><span class="nb">test</span><span class="w"> </span>with<span class="w"> </span>following<span class="w"> </span>options:
Number<span class="w"> </span>of<span class="w"> </span>threads:<span class="w"> </span><span class="m">150</span>
Initializing<span class="w"> </span>random<span class="w"> </span>number<span class="w"> </span>generator<span class="w"> </span>from<span class="w"> </span>current<span class="w"> </span><span class="nb">time</span>
Initializing<span class="w"> </span>worker<span class="w"> </span>threads...
Threads<span class="w"> </span>started!
SQL<span class="w"> </span>statistics:
<span class="w">    </span>queries<span class="w"> </span>performed:
<span class="w">        </span>read:<span class="w">                            </span><span class="m">527282</span>
<span class="w">        </span>write:<span class="w">                           </span><span class="m">0</span>
<span class="w">        </span>other:<span class="w">                           </span><span class="m">75326</span>
<span class="w">        </span>total:<span class="w">                           </span><span class="m">602608</span>
<span class="w">    </span>transactions:<span class="w">                        </span><span class="m">37663</span><span class="w">  </span><span class="o">(</span><span class="m">3756</span>.49<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>queries:<span class="w">                             </span><span class="m">602608</span><span class="w"> </span><span class="o">(</span><span class="m">60103</span>.86<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>ignored<span class="w"> </span>errors:<span class="w">                      </span><span class="m">0</span><span class="w">      </span><span class="o">(</span><span class="m">0</span>.00<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>reconnects:<span class="w">                          </span><span class="m">0</span><span class="w">      </span><span class="o">(</span><span class="m">0</span>.00<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
General<span class="w"> </span>statistics:
<span class="w">    </span>total<span class="w"> </span>time:<span class="w">                          </span><span class="m">10</span>.0247s
<span class="w">    </span>total<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>events:<span class="w">              </span><span class="m">37663</span>
Latency<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:
<span class="w">         </span>min:<span class="w">                                  </span><span class="m">4</span>.30
<span class="w">         </span>avg:<span class="w">                                 </span><span class="m">39</span>.88
<span class="w">         </span>max:<span class="w">                               </span><span class="m">8371</span>.55
<span class="w">         </span>95th<span class="w"> </span>percentile:<span class="w">                     </span><span class="m">82</span>.96
<span class="w">         </span>sum:<span class="w">                            </span><span class="m">1501845</span>.63
Threads<span class="w"> </span>fairness:
<span class="w">    </span>events<span class="w"> </span><span class="o">(</span>avg/stddev<span class="o">)</span>:<span class="w">           </span><span class="m">251</span>.0867/87.82
<span class="w">    </span>execution<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>avg/stddev<span class="o">)</span>:<span class="w">   </span><span class="m">10</span>.0123/0.01
</pre></div>

<p>With dramatic results! Our cluster is now able to process 60K queries
per second! How far can we take this? Well, if you noticed our node
count at the start we have five nodes in our k8s cluster, so lets make
our Galera cluster match that:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>edit<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml
galeraservice.galera.database.coreos.com/galera-example<span class="w"> </span>edited
$<span class="w"> </span>kubectl<span class="w"> </span>describe<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-i<span class="w"> </span>size
Galera<span class="w"> </span>_<span class="w"> </span>Cluster<span class="w"> </span>_<span class="w"> </span>Size:<span class="w"> </span><span class="m">5</span>
</pre></div>

<p>The Ansible operator starts growing the Galera cluster...:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>pods
NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>35m
galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>32m
galera-node-0002<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>7m
galera-node-0003<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>7m
galera-node-0004<span class="w"> </span><span class="m">0</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>38s
galera-node-0005<span class="w"> </span><span class="m">0</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>34s
</pre></div>

<p>And again after about a minute or so we have a Galera cluster with five
pods ready to serve queries:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>pods
NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>36m
galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>33m
galera-node-0002<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>8m
galera-node-0003<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>8m
galera-node-0004<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>1m
galera-node-0005<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">1</span><span class="w"> </span>1m
</pre></div>

<p>Oddly, the fifth node had a problem, but OpenShift retried it after it
failed and it came up and into the cluster. Great!</p>
<p>So let's rerun our same test once again:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>sysbench<span class="w"> </span>--db-driver<span class="o">=</span>mysql<span class="w"> </span>--threads<span class="o">=</span><span class="m">150</span><span class="w"> </span>--mysql-host<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_IP</span><span class="si">}</span><span class="w"> </span>--mysql-port<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_PORT</span><span class="si">}</span><span class="w"> </span>--mysql-user<span class="o">=</span>root<span class="w"> </span>--mysql-password<span class="o">=</span><span class="w"> </span>--mysql-ignore-errors<span class="o">=</span>all<span class="w"> </span>/usr/share/sysbench/oltp_read_only.lua<span class="w"> </span>run
sysbench<span class="w"> </span><span class="m">1</span>.0.9<span class="w"> </span><span class="o">(</span>using<span class="w"> </span>system<span class="w"> </span>LuaJIT<span class="w"> </span><span class="m">2</span>.0.4<span class="o">)</span>
Running<span class="w"> </span>the<span class="w"> </span><span class="nb">test</span><span class="w"> </span>with<span class="w"> </span>following<span class="w"> </span>options:
Number<span class="w"> </span>of<span class="w"> </span>threads:<span class="w"> </span><span class="m">150</span>
Initializing<span class="w"> </span>random<span class="w"> </span>number<span class="w"> </span>generator<span class="w"> </span>from<span class="w"> </span>current<span class="w"> </span><span class="nb">time</span>
Initializing<span class="w"> </span>worker<span class="w"> </span>threads...
Threads<span class="w"> </span>started!
SQL<span class="w"> </span>statistics:
queries<span class="w"> </span>performed:
<span class="w">        </span>read:<span class="w">                            </span><span class="m">869260</span>
<span class="w">        </span>write:<span class="w">                           </span><span class="m">0</span>
<span class="w">        </span>other:<span class="w">                           </span><span class="m">124180</span>
<span class="w">        </span>total:<span class="w">                           </span><span class="m">993440</span>
<span class="w">    </span>transactions:<span class="w">                        </span><span class="m">62090</span><span class="w">  </span><span class="o">(</span><span class="m">6196</span>.82<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>queries:<span class="w">                             </span><span class="m">993440</span><span class="w"> </span><span class="o">(</span><span class="m">99149</span>.17<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>ignored<span class="w"> </span>errors:<span class="w">                      </span><span class="m">0</span><span class="w">      </span><span class="o">(</span><span class="m">0</span>.00<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>reconnects:<span class="w">                          </span><span class="m">0</span><span class="w">      </span><span class="o">(</span><span class="m">0</span>.00<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
General<span class="w"> </span>statistics:
<span class="w">    </span>total<span class="w"> </span>time:<span class="w">                          </span><span class="m">10</span>.0183s
<span class="w">    </span>total<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>events:<span class="w">              </span><span class="m">62090</span>
Latency<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:
<span class="w">         </span>min:<span class="w">                                  </span><span class="m">5</span>.41
<span class="w">         </span>avg:<span class="w">                                 </span><span class="m">24</span>.18
<span class="w">         </span>max:<span class="w">                                </span><span class="m">159</span>.70
<span class="w">         </span>95th<span class="w"> </span>percentile:<span class="w">                     </span><span class="m">46</span>.63
<span class="w">         </span>sum:<span class="w">                            </span><span class="m">1501042</span>.93
Threads<span class="w"> </span>fairness:
<span class="w">    </span>events<span class="w"> </span><span class="o">(</span>avg/stddev<span class="o">)</span>:<span class="w">           </span><span class="m">413</span>.9333/78.17
<span class="w">    </span>execution<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>avg/stddev<span class="o">)</span>:<span class="w">   </span><span class="m">10</span>.0070/0.00
</pre></div>

<p>And we're hitting 100K queries per second. Our cluster has thus-far
scaled linearly with the number of nodes we've spun up. At this point,
we've maxed out the resources of our OpenShift cluster, and spinning up
more Galera nodes doesn't help:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>edit<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml
galeraservice.galera.database.coreos.com/galera-example<span class="w"> </span>edited
$<span class="w"> </span>kubectl<span class="w"> </span>describe<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-i<span class="w"> </span>size
Galera<span class="w"> </span>_<span class="w"> </span>Cluster<span class="w"> </span>_<span class="w"> </span>Size:<span class="w"> </span><span class="m">9</span>

$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>pods
NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>44m
galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>41m
galera-node-0002<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>16m
galera-node-0003<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>16m
galera-node-0004<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>9m
galera-node-0005<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">1</span><span class="w"> </span>9m
galera-node-0006<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>1m
galera-node-0007<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>1m
galera-node-0008<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>1m
galera-node-0009<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>1m

$<span class="w"> </span>sysbench<span class="w"> </span>--db-driver<span class="o">=</span>mysql<span class="w"> </span>--threads<span class="o">=</span><span class="m">150</span><span class="w"> </span>--mysql-host<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_IP</span><span class="si">}</span><span class="w"> </span>--mysql-port<span class="o">=</span><span class="si">${</span><span class="nv">MYSQL_PORT</span><span class="si">}</span><span class="w"> </span>--mysql-user<span class="o">=</span>root<span class="w"> </span>--mysql-password<span class="o">=</span><span class="w"> </span>--mysql-ignore-errors<span class="o">=</span>all<span class="w"> </span>/usr/share/sysbench/oltp_read_only.lua<span class="w"> </span>run
sysbench<span class="w"> </span><span class="m">1</span>.0.9<span class="w"> </span><span class="o">(</span>using<span class="w"> </span>system<span class="w"> </span>LuaJIT<span class="w"> </span><span class="m">2</span>.0.4<span class="o">)</span>
Running<span class="w"> </span>the<span class="w"> </span><span class="nb">test</span><span class="w"> </span>with<span class="w"> </span>following<span class="w"> </span>options:
Number<span class="w"> </span>of<span class="w"> </span>threads:<span class="w"> </span><span class="m">150</span>
Initializing<span class="w"> </span>random<span class="w"> </span>number<span class="w"> </span>generator<span class="w"> </span>from<span class="w"> </span>current<span class="w"> </span><span class="nb">time</span>
Initializing<span class="w"> </span>worker<span class="w"> </span>threads...
Threads<span class="w"> </span>started!
SQL<span class="w"> </span>statistics:
<span class="w">    </span>queries<span class="w"> </span>performed:
<span class="w">        </span>read:<span class="w">                            </span><span class="m">841260</span>
<span class="w">        </span>write:<span class="w">                           </span><span class="m">0</span>
<span class="w">        </span>other:<span class="w">                           </span><span class="m">120180</span>
<span class="w">        </span>total:<span class="w">                           </span><span class="m">961440</span>
<span class="w">    </span>transactions:<span class="w">                        </span><span class="m">60090</span><span class="w">  </span><span class="o">(</span><span class="m">5995</span>.71<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>queries:<span class="w">                             </span><span class="m">961440</span><span class="w"> </span><span class="o">(</span><span class="m">95931</span>.35<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>ignored<span class="w"> </span>errors:<span class="w">                      </span><span class="m">0</span><span class="w">      </span><span class="o">(</span><span class="m">0</span>.00<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
<span class="w">    </span>reconnects:<span class="w">                          </span><span class="m">0</span><span class="w">      </span><span class="o">(</span><span class="m">0</span>.00<span class="w"> </span>per<span class="w"> </span>sec.<span class="o">)</span>
General<span class="w"> </span>statistics:
<span class="w">    </span>total<span class="w"> </span>time:<span class="w">                          </span><span class="m">10</span>.0208s
<span class="w">    </span>total<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>events:<span class="w">              </span><span class="m">60090</span>
Latency<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:
<span class="w">         </span>min:<span class="w">                                  </span><span class="m">5</span>.24
<span class="w">         </span>avg:<span class="w">                                 </span><span class="m">24</span>.98
<span class="w">         </span>max:<span class="w">                                </span><span class="m">192</span>.46
<span class="w">         </span>95th<span class="w"> </span>percentile:<span class="w">                     </span><span class="m">57</span>.87
<span class="w">         </span>sum:<span class="w">                            </span><span class="m">1501266</span>.08
Threads<span class="w"> </span>fairness:
<span class="w">    </span>events<span class="w"> </span><span class="o">(</span>avg/stddev<span class="o">)</span>:<span class="w">           </span><span class="m">400</span>.6000/134.04
<span class="w">    </span>execution<span class="w"> </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>avg/stddev<span class="o">)</span>:<span class="w">   </span><span class="m">10</span>.0084/0.01
</pre></div>

<p>Performance actually decreased a bit! This shows that MySQL/MariaDB are
pretty resource-intensive, so if you want to continue scaling out the
performance you may need to add more OpenShift cluster resources. But at
this point, our cluster is serving nearly 5x the traffic as when we
originally started it up. Continued tuning of MySQL/MariaDB and Galera
could extend that and allow us to increase performance further. However
the goal here was to show how to create an Ansible operator to control a
very complex, data-oriented application.</p>
<h3>Scaling the cluster down</h3>
<p>Since those extra nodes aren't helping out (other than providing a bit
more redundancy in the event of a failure), lets scale the cluster back
down to five nodes:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>edit<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml
galeraservice.galera.database.coreos.com/galera-example<span class="w"> </span>edited
$<span class="w"> </span>kubectl<span class="w"> </span>describe<span class="w"> </span>-f<span class="w"> </span>deploy/cr.yaml<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-i<span class="w"> </span>size
Galera<span class="w"> </span>_<span class="w"> </span>Cluster<span class="w"> </span>_<span class="w"> </span>Size:<span class="w"> </span><span class="m">5</span>
</pre></div>

<p>After a short while, we see the operator begin to terminate pods that
are no longer required:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>pods
NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>46m
galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>43m
galera-node-0002<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>18m
galera-node-0003<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>18m
galera-node-0004<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>11m
galera-node-0005<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">1</span><span class="w"> </span>11m
galera-node-0006<span class="w"> </span><span class="m">0</span>/1<span class="w"> </span>Terminating<span class="w"> </span><span class="m">0</span><span class="w"> </span>3m
galera-node-0007<span class="w"> </span><span class="m">0</span>/1<span class="w"> </span>Terminating<span class="w"> </span><span class="m">0</span><span class="w"> </span>3m
galera-node-0008<span class="w"> </span><span class="m">0</span>/1<span class="w"> </span>Terminating<span class="w"> </span><span class="m">0</span><span class="w"> </span>3m
galera-node-0009<span class="w"> </span><span class="m">0</span>/1<span class="w"> </span>Terminating<span class="w"> </span><span class="m">0</span><span class="w"> </span>3m
</pre></div>

<h3>Disaster recovery</h3>
<p>Now, let's add some chaos. Looking at our first worker <code>xx-yy-zz-2</code>, we can see which pods are running on the node:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>describe<span class="w"> </span>node<span class="w"> </span>ec2-xx-yy-zz-2.us-east-2.compute.amazonaws.com
...
Non-terminated<span class="w"> </span>Pods:<span class="w"> </span><span class="o">(</span><span class="m">5</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>total<span class="o">)</span>
Namespace<span class="w"> </span>Name<span class="w"> </span>CPU<span class="w"> </span>Requests<span class="w"> </span>CPU<span class="w"> </span>Limits<span class="w"> </span>Memory<span class="w"> </span>Requests<span class="w"> </span>Memory<span class="w"> </span>Limits
---------<span class="w"> </span>----<span class="w"> </span>------------<span class="w"> </span>----------<span class="w"> </span>---------------<span class="w"> </span>-------------
openshift-monitoring<span class="w"> </span>node-exporter-bqnzv<span class="w"> </span>10m<span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span>20m<span class="w"> </span><span class="o">(</span><span class="m">1</span>%<span class="o">)</span><span class="w"> </span>20Mi<span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span>40Mi<span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span>
openshift-node<span class="w"> </span>sync-hjtmj<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span>
openshift-sdn<span class="w"> </span>ovs-55hw4<span class="w"> </span>100m<span class="w"> </span><span class="o">(</span><span class="m">5</span>%<span class="o">)</span><span class="w"> </span>200m<span class="w"> </span><span class="o">(</span><span class="m">10</span>%<span class="o">)</span><span class="w"> </span>300Mi<span class="w"> </span><span class="o">(</span><span class="m">4</span>%<span class="o">)</span><span class="w"> </span>400Mi<span class="w"> </span><span class="o">(</span><span class="m">5</span>%<span class="o">)</span>
openshift-sdn<span class="w"> </span>sdn-rd7kp<span class="w"> </span>100m<span class="w"> </span><span class="o">(</span><span class="m">5</span>%<span class="o">)</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span>200Mi<span class="w"> </span><span class="o">(</span><span class="m">2</span>%<span class="o">)</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span>
<span class="nb">test</span><span class="w"> </span>galera-node-0004<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">(</span><span class="m">0</span>%<span class="o">)</span>
...
</pre></div>

<p>So galera-node-0004 is running here, along with some other
infrastructure bits. Lets restart it from the AWS EC2 console and see
what happens...</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>nodes
NAME<span class="w"> </span>STATUS<span class="w"> </span>AGE
ec2-xx-yy-zz-1.us-east-2.compute.amazonaws.com<span class="w"> </span>Ready<span class="w"> </span>1d
ec2-xx-yy-zz-2.us-east-2.compute.amazonaws.com<span class="w"> </span>NotReady<span class="w"> </span>1d
ec2-xx-yy-zz-3.us-east-2.compute.amazonaws.com<span class="w"> </span>Ready<span class="w"> </span>1d
ec2-xx-yy-zz-4.us-east-2.compute.amazonaws.com<span class="w"> </span>Ready<span class="w"> </span>1d
ec2-xx-yy-zz-5.us-east-2.compute.amazonaws.com<span class="w"> </span>Ready<span class="w"> </span>1d
ec2-xx-yy-zz-6.us-east-2.compute.amazonaws.com<span class="w"> </span>Ready<span class="w"> </span>1d
ec2-xx-yy-zz-7.us-east-2.compute.amazonaws.com<span class="w"> </span>Ready<span class="w"> </span>1d
ec2-xx-yy-zz-8.us-east-2.compute.amazonaws.com<span class="w"> </span>Ready<span class="w"> </span>1d
</pre></div>

<p>Eventually, we see galera-node-0004 enter an unknown state:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>pods
NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>50m
galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>47m
galera-node-0002<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>22m
galera-node-0003<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>22m
galera-node-0004<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Unknown<span class="w"> </span><span class="m">0</span><span class="w"> </span>16m
galera-node-0005<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">1</span><span class="w"> </span>16m
</pre></div>

<p>And in a while the pod will be terminated, after which the Ansible
operator will restart it:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>pods
NAME<span class="w"> </span>READY<span class="w"> </span>STATUS<span class="w"> </span>RESTARTS<span class="w"> </span>AGE
galera-ansible-operator-bc6cd548-46b2r<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">5</span><span class="w"> </span>55m
galera-node-0001<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>52m
galera-node-0002<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>27m
galera-node-0003<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">0</span><span class="w"> </span>27m
galera-node-0004<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">1</span><span class="w"> </span>1m
galera-node-0005<span class="w"> </span><span class="m">1</span>/1<span class="w"> </span>Running<span class="w"> </span><span class="m">1</span><span class="w"> </span>21m
</pre></div>

<p>... and our cluster is back to its requested capacity!</p>
<h3>Cleanup</h3>
<p>Since this is a test we'll want to clean up after ourselves. When we're
done we use the delete_operator.sh script to remove the custom resource
and the operator deployment:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>./delete_operator.sh
galeraservice.galera.database.coreos.com<span class="w"> </span><span class="s2">"galera-example"</span><span class="w"> </span>deleted
deployment.apps<span class="w"> </span><span class="s2">"galera-ansible-operator"</span><span class="w"> </span>deleted
</pre></div>

<p>In a couple of minutes, everything is gone:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>oc<span class="w"> </span>get<span class="w"> </span>all
NAME<span class="w"> </span>DOCKER<span class="w"> </span>REPO<span class="w"> </span>TAGS<span class="w"> </span>UPDATED
is/galera-ansible-operator<span class="w"> </span>docker-registry-default.router...:5000/test/galera-ansible-operator<span class="w"> </span>latest<span class="w"> </span><span class="m">4</span><span class="w"> </span>hours<span class="w"> </span>ago
</pre></div>

<h2>Summary</h2>
<p>The Galera operator is a work in progress and is most definitely not
ready for production. If you'd like to view the playbooks themselves,
you can see the code here:</p>
<p><a href="https://github.com/water-hole/galera-ansible-operator">https://github.com/water-hole/galera-ansible-operator</a></p>
<p>We're going to be continuing development on this with the goal of
making it the de facto example for other data storage applications.
Thanks for reading!</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="kubernetes-operators-ansible-deep-dive-part-1/" class="u-url">Kubernetes Operators with Ansible Deep Dive, Part 1</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/james-cammarata/">James Cammarata</a>
              </span>
            </p>
            <p class="dateline">
              <a href="kubernetes-operators-ansible-deep-dive-part-1/" rel="bookmark">
                <time class="published dt-published" datetime="2019-07-25T00:00:00Z" itemprop="datePublished" title="2019-07-25 00:00">2019-07-25 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>Kubernetes Operators with Ansible Deep Dive, Part 1</h2>
<p>This deep dive series assumes the reader has access to a Kubernetes test
environment. A tool like minikube is an acceptable platform for the
purposes of this article. If you are an existing Red Hat customer,
another option is spinning up an OpenShift cluster
through <a href="https://cloud.redhat.com/">cloud.redhat.com</a>. This
SaaS portal makes trying OpenShift a turnkey operation.</p>
<p>In this part of this deep dive series, we'll:</p>
<ol>
<li>Take a look at operators overall, and what they do in OpenShift/Kubernetes.</li>
<li>Take a quick look at the Operator SDK, and why you'd want to use an Ansible operator rather than other kinds of operators provided by the SDK.</li>
<li>And finally, how Ansible Operators are structured and the relevant files created by the Operator SDK.</li>
</ol>
<h3>What Are Operators?</h3>
<p>For those who may not be very familiar with Kubernetes, it is, in its
most simplistic description - a resource manager. Users specify how much
of a given resource they want and Kubernetes manages those resources to
achieve the state the user specified. These resources can be pods (which
contain one or more containers), persistent volumes, or even custom
resources defined by users.</p>
<p>This makes Kubernetes useful for managing resources that don't contain
any state (like pods of web servers or load balancing resources).
However, Kubernetes doesn't provide any built-in logic for managing
resources like databases or caches which are stateful and sensitive to
restarts. Operators were created to bridge this gap by providing a way
for users to specify a piece of code (traditionally written in Golang)
tied to <a href="https://docs.openshift.com/container-platform/4.1/applications/crds/crd-extending-api-with-crds.html">custom resource definitions</a>
in Kubernetes.</p>
<p>Operators were so named because they allow you to embed your operational logic of an application into an automated manager running on Kubernetes/OpenShift.</p>
<h3>The Operator SDK, and a quick overview of Ansible Operators</h3>
<p>Red Hat created the <a href="https://blog.openshift.com/introducing-the-operator-framework/%26sa=D%26ust=1563546779219000">Operator Framework</a>
to make the job of creating and managing operators easier across their full
lifetime. As part of the framework, the Operator SDK is tasked with
creating and building operators in an automated manner for users. Over
time it has grown to add several operator types. In 2018, we began work
on adding the Ansible Operator type to the SDK. We want to make it
easier to build operators in Kubernetes environments based on Ansible.</p>
<h4>Why use Ansible for Operators?</h4>
<p>At first, operators were written in Golang. This immediately sets the
bar somewhat high for anyone who wants to write an operator --- someone
has to know a relatively low-level programming language to get started.
On top of this, you must also be familiar with Kubernetes internals,
such as the API and how events are generated for resources.</p>
<p>The Ansible Operator was created to address this short-coming. The
Ansible Operator consists of two main pieces:</p>
<ol>
<li>A small chunk of Golang code, which handles the interface between Kubernetes/OpenShift and the operator.</li>
<li>A container, which receives events from the above code and runs Ansible Playbooks as required.</li>
</ol>
<p>That's it! The Ansible and Operator SDK abstract away all of the
difficult parts of writing an operator and allows you to focus on what
matters --- managing your applications. If you already have a large base
of Ansible knowledge in your organization, you can immediately begin
managing applications using Ansible Operator. A further added bonus of
using Ansible for your operators is that you immediately have access to
any module that Ansible can run. This allows folks to incorporate
off-cluster management tasks related to your application. For example:</p>
<ol>
<li>Creating DNS entries for your newly deployed applications</li>
<li>Spinning up resources external to your cluster, such as storage or
    networking</li>
<li>More easily do off-site backups to external cloud services</li>
<li>Manage external load balancing based on custom metrics</li>
</ol>
<p>There are a number of possibilities that Kubernetes Operators written with Ansible can provide a potential solution for.</p>
<h3>Creating a Kubernetes Operator with Ansible from scratch</h3>
<p>First, <a href="https://github.com/operator-framework/operator-sdk/blob/master/doc/user/install-operator-sdk.md">install the Operator SDK</a>
following their instructions. Once the install is complete, we can create a new operator with the following command:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>operator-sdk<span class="w"> </span>new<span class="w"> </span>test-operator<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-version<span class="o">=</span>test.ansible-operator.com/v1<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--kind<span class="o">=</span>Test<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--type<span class="o">=</span>ansible

INFO<span class="o">[</span><span class="m">0000</span><span class="o">]</span><span class="w"> </span>Creating<span class="w"> </span>new<span class="w"> </span>Ansible<span class="w"> </span>operator<span class="w"> </span><span class="s1">'test-operator'</span>.
...
INFO<span class="o">[</span><span class="m">0000</span><span class="o">]</span><span class="w"> </span>Project<span class="w"> </span>creation<span class="w"> </span>complete.

$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>test-operator/
</pre></div>

<h3>Kubernetes Operator with Ansible structure and files</h3>
<p>[Now that we have our Operator skeleton, let's take a look at some of
the main files used when deploying Operators in general, as well as what
the Ansible Operator type generated specifically. These are the:</p>
<ol>
<li>
<code>watches.yaml</code> file.</li>
<li>
<code>build</code> directory.</li>
<li>
<code>deploy</code> directory.</li>
<li>
<code>roles</code> directory.</li>
</ol>
<p>One other directory is present here as well: the molecule directory,
which contains files to automate testing your roles/playbooks
using <a href="https://molecule.readthedocs.io/en/stable/%26sa=D%26ust=1563546779225000">Molecule</a>.
We will not be covering the use of Molecule here it's noted for the sake
of being complete.</p>
<p>If you run <code>ls -l</code> in the above <code>test-operator</code> directory, you see these files/directories there after creating the new operator skeleton.</p>
<h4>The watches.yaml file</h4>
<p>This file is used by the Ansible Operator to tell Kubernetes/OpenShift
which custom resources (based on the Group/Version/Kind fields) the
operator is responsible in handling. It is the glue that ties our custom
code to the Kubernetes API:</p>
<div class="code"><pre class="code literal-block"><span class="nn">---</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="w">  </span><span class="nt">group</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">test.ansible-operator.com</span>
<span class="w">  </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Test</span>
<span class="w">  </span><span class="nt">role</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/opt/ansible/roles/test</span>
</pre></div>

<p>specifying any other playbook boilerplate. However if you are running
more than one role in your operator you can change that line to be:</p>
<div class="code"><pre class="code literal-block">playbook:<span class="w"> </span>/opt/ansible/playbook.yaml
</pre></div>

<p>Also, you'll need to tweak the <code>build/Dockerfile</code> (more on this below) to
copy the playbook into the container so add this line:</p>
<div class="code"><pre class="code literal-block">COPY<span class="w"> </span>playbook.yaml<span class="w"> </span><span class="si">${</span><span class="nv">HOME</span><span class="si">}</span>/playbook.yaml
</pre></div>

<p>You would then create the specified playbook in the same directory as
the <code>watches.yaml</code> file.</p>
<h4>The build directory</h4>
<p>This directory contains a few files related to building the operator
artifact. Because operators are just another application to
OpenShift/Kubernetes, this artifact is a container built using
a <code>Dockerfile</code>. The other files here are related to testing via Molecule, which we are not
going to cover in this blog series.</p>
<p>The <code>Dockerfile</code> is very simple, so we won't delve into it much other than to say it is based on
the ansible-operator image from <a href="https://quay.io/%26sa=D%26ust=1563546779229000">quay.io</a>, and copies the roles and watches.yml file into
the container image.</p>
<h4>The deploy directory</h4>
<p>This directory contains YAML files for deploying the operator into
OpenShift/K8s using the <code>oc</code> CLI commands.</p>
<p>The CustomResourceDefinition (CRD) and CustomResource (CR) are defined
in the <code>deploy/crds/</code> directory. The CRD is what
the <code>watches.yaml</code> file references, meaning
all instances (CRs) of this definition will be controlled by our operator.</p>
<p>The CRD is defined in <code>deploy/crds/test_v1_test_crd.yaml</code> and is mostly boilerplate
for OpenShift/Kubernetes:</p>
<div class="code"><pre class="code literal-block"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">apiextensions.k8s.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CustomResourceDefinition</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tests.test.ansible-operator.com</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</pre></div>

<p>You can see the operator-sdk command above filled in most of these
fields with the values we specified. By themselves, CRDs are not very
useful, you need actual instances of what they define --- this is what
CustomResources do. Our CustomResource (CR) is defined
in <code>deploy/crds/test_v1_test_cr.yaml</code>, and is relatively short
(compared to the other YAML files, anyway):</p>
<div class="code"><pre class="code literal-block"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">test.ansible-operator.com/v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Test</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">example-test</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
</pre></div>

<p>Each of the values set under the spec entry become variables passed into
Ansible as extra variables. Using these, we can customize the behavior
of our operator. The default example creates an entry named size, which
we can use in our roles to dynamically scale the application our
operator is managing.</p>
<p>The <code>deploy/role.yaml</code> and <code>deploy/role_binding.yaml</code>
(not shown), define some RBAC controls which give your login access to
manage the custom resources defined above. Role Based Access Control
(RBAC) is not covered in this post, so again we're just mentioning them
for completeness.</p>
<p>Finally, the <code>deploy/operator.yaml</code>:</p>
<div class="code"><pre class="code literal-block"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">test-operator</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</pre></div>

<p>This file is quite long, but mainly it creates a new Deployment
resource in OpenShift/Kubernetes, which helps ensure that our operator
stays up and running.</p>
<h4>The roles directory</h4>
<p>This is the directory where you place any roles you wish to include
with your operator, and should be familiar to experienced Ansible users.
As noted above, this directory is copied completely into the Ansible
Operator container, and roles here can be referenced in the <code>watches.yaml</code>
file or other playbooks you include.</p>
<p>Roles commonly use the <code>k8s</code> module (included in Red
Hat Ansible Automation since the 2.6 release) to manage resources on the
cluster. If you are familiar with Kubernetes resource files, this module
will be very intuitive (the YAML from a resource file can be copy/pasted
directly as the input to this module). To learn more, you can read the
documentation for the k8s module here:</p>
<p><a href="https://docs.ansible.com/ansible/latest/modules/k8s_module.html%26sa=D%26ust=1563546779234000">https://docs.ansible.com/ansible/latest/modules/k8s_module.html</a></p>
<h3>Summary</h3>
<p>This concludes our deep dive into operators, Operator SDK, and Ansible
Operator creation and structure. Operators written using Ansible give
you the power of operators in general, while allowing you to leverage
preexisting Ansible expertise to quickly get up to speed on deploying
applications on OpenShift or Kubernetes.</p>
          </div>
      </article><br><hr>
<br><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title">
            <a href="the-future-of-ansible-content-delivery/" class="u-url">The Future of Ansible Content Delivery</a>
          </h1>
          <div class="metadata">
            <p class="byline author vcard">
              <span class="byline-name fn" itemprop="author">
                  <a href="../authors/dylan-silva/">Dylan Silva</a>
              </span>
            </p>
            <p class="dateline">
              <a href="the-future-of-ansible-content-delivery/" rel="bookmark">
                <time class="published dt-published" datetime="2019-07-23T00:00:00Z" itemprop="datePublished" title="2019-07-23 00:00">2019-07-23 00:00</time></a>
            </p>
          </div>
        </header><div class="p-summary entry-summary">
            <h2>The Future of Ansible Content Delivery</h2>
<p>Everyday, I'm in awe of what Ansible has grown to be. The incredible
growth of the community and viral adoption of the technology has
resulted in a content management challenge for the project.</p>
<p>I don't want to echo a lot of what's been said by our dear friend
<a href="https://jpmens.net/2019/06/21/i-care-about-ansible/">Jan-Piet Mens</a>
or our incredible Community team, but give me a moment to take a shot at it.</p>
<p>Our main challenge is rooted in the ability to scale. The volume of pull
requests and issues we see day to day severely outweigh the ability of
the Ansible community to keep up with that rate of change.</p>
<p>As a result, we are embarking on a journey. This journey is one that we
know that the community, both our content creators and content
consumers, will be interested in hearing about.</p>
<p>This New World Order (tongue in cheek), as we've been calling it, is a
model that will allow for us to empower the community of contributors of
Ansible content (read: modules, plugins, and roles) to provide their
content at their own pace.</p>
<p>To do this, we have made some changes to how Ansible leverages content
that is not "shipped" with it. In short, Ansible content will not have
to be a part of a milestone Core release of the Engine itself. We will
be leveraging a delivery process and content structure/format that helps
alleviate a lot of the ambiguity and pain that is currently there due to
tying plugins to the Core Engine.</p>
<p>The cornerstone of this journey is something you may have heard
rumblings of out in the interwebs. This thing is called a Ansible
Content Collection, or Collection(s), for short.</p>
<p>To create Ansible Content Collections, we took a look at a lot of things
already in practice. We looked at other tools, other packaging formats,
delivery engines, repositories, and ultimately, ourselves. In all of
that investigation we feel we have come up with a pretty sound spec.
Below we cover some details of that.</p>
<p>A Collection is a strict project/directory structure for Ansible
Content. Similar to the role directory structure; we are now
highlighting what is important to Ansible Playbook execution. Here's a
graphic of that spec, created by my teammate, Tim Appnel.</p>
<p><img alt="Screenshot_future-of-content-1" src="../images/posts/archive/screenshot_future-of-content-1.webp"></p>
<p>As you can see, this structure does look very similar to roles. There
are some slight differences though. Notice that the roles directory no
longer contains a library folder? The idea here is that a Collection
itself is the true encapsulation of every piece of content relevant to
it, and the playbook that is executing that content. So we've taken the
libraries out of the various roles that could live in a collection, and
placed them at the top level in the plugins directory. There, all types
of plugins (yes modules are there because modules are actually plugins)
will be usable by the roles and ultimately all playbooks that could
potentially call them. Because this content will be "installed" in a
location that the Engine is aware of, and will know to look for content
that is being called in the playbook.</p>
<p>Also, with these changes, we have introduced some namespacing concepts
into playbooks as well. Here's another graphic, by Tim, that is a
snippet out of a playbook that highlights that namespacing.</p>
<p><img alt="Screenshot_future-of-content-2" src="../images/posts/archive/screenshot_future-of-content-2.png"></p>
<p>So what we've got here is a very simple playbook. In this playbook we
have highlighted the list of Collections that we're interested in using.
For each task, we are using the FQCN (Fully Qualified Collection
Namespace) path to the module. Of course, we still want to make this
simple. So playbook creators won't have to always fully qualify their
content path. As you see in the fourth task, creators can still use the
shorthand name of a module. Ansible will search the path of collections
in a first come first serve approach, as defined in Ansible
configuration or within the play itself.</p>
<p>That's about all I've got for going into Collections.</p>
<p>Happy Automating folks!</p>
          </div>
      </article><br><hr>
<br>
</div>
          <ul class="pager postindexpager clearfix">
<li class="previous"><a href="index-5.html" rel="prev">Newer posts</a></li>
            <li class="next"><a href="index-3.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content-->
</div>
        <div class="content-slim redhat-footer">
      <div class="footer-left">
        <ul class="footer-left-links">
<li>
            <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CC BY-SA 4.0</a>
          </li>
          <li>
            <a href="https://www.redhat.com/en/about/privacy-policy" target="_blank">Privacy policy</a>
          </li>
          <li>
            <a href="https://docs.ansible.com/ansible/latest/community/code_of_conduct.html" target="_blank">Code of conduct</a>
          </li>
        </ul>
</div>
      <div class="footer-right">
        <span class="redhat">Powered by</span>
        <span class="redhat-logo">
          <a href="https://www.redhat.com/en/technologies/management/ansible" target="_blank">
            <img src="../assets/images/redhat_reversed.svg" alt="Red Hat logo." width="96" height="28"></a>
        </span>
      </div>
    </div>

</div>

            <script src="../assets/js/jquery.min.js"></script><script src="../assets/js/popper.min.js"></script><script src="../assets/js/bootstrap.min.js"></script><script src="../assets/js/baguetteBox.min.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script><script src="../assets/js/clipboard.min.js" type="text/javascript"></script><script src="../assets/js/clipboard.js" type="text/javascript"></script>
</body>
</html>
